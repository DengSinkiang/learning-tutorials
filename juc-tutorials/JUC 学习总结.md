###  synchonized

- 一句话介绍 synchonized
  - JVM 会自动通过使用 monitor 来加锁和解锁，保证了同时只有一个线程可以执行指定代码，从而保证了线程安全，同时具有可重入和不可中断的性质
- synchonized 的作用
  - 能够保证在同一时刻最多只有一个线程执行该段代码，以达到保证并发安全的效果
- synchonized 的两个用法
  - 对象锁
    - 包括方法锁（synchonized 修饰普通方法，默认锁对象为 this 当前实例对象）和同步代码块锁（自己指定锁对象）
  - 类锁
    - 指 synchonized 修饰静态的方法或指定锁为 Class 对象
    - Java 类可能有很多个对象，但只有一个 Class 对象
    - 本质：所谓的类锁：Class 对象的锁
    - 类锁只能在同一时刻被一个对象拥有
- synchonized 的原理
  - https://juejin.cn/post/6844903805121740814
- 1.两个线程同时访问一个对象的同步方法
  - 争抢的是同一把锁，需要相互等待
- 2.两个线程同时访问两个对象的同步方法
  - 锁对象不是同一个，并行执行
- 3.两个线程访问的是 synchonized 的静态方法
  - 争抢的是同一把锁，需要相互等待
- 4.同时访问同步方法与非同步方法
  - 并行执行，非同步方法不受影响
- 5.访问同一个对象的不同的普通同步方法
  - 锁对象为 this 当前实例对象，需要相互等待
- 6.同时访问静态 synchonized 和非静态 synchonized 方法
  - 锁对象不是同一个，并行执行
- 7.方法抛异常后，会释放锁
- 8.目前我进入到一个被 synchonized 修饰的方法中，在方法里调用了另外一个未被 synchonized 修饰的方法，此时是线程不安全的。因为一旦出了本方法进入另外一个未被 synchonized 修饰的方法中，而该方法可以同时被多个线程同时访问，所以是线程不安全的
- 总结
  - 一把锁只能同时被一个线程获取，没有获取到锁的线程必须等待（对应 1 和 5）
  - 每个实例都对应有自己的一把锁，不同实例之间互不影响；例外：锁对象是 *.class 以及 synchonized 修饰的是 static 方法时，所有对象共用同一把类锁（对应 2、3、4、6）
  - 无论是方法正常执行完毕或者方法抛出异常，都会释放锁（对应 7）
- 性质
  - 可重入
    - 指同一线程的外层函数获取到锁之后，内层函数可以直接再次获取到锁
    - 避免死锁、提升封装性
    - 粒度：线程而非调用（用 3 种情况说明和 pthead 的区别）
      - 情况一：证明同一个方法是可重入的
      - 情况二：证明可重入不要求是同一个方法
      - 情况三：证明可重入不要求是一个类中的
  - 不可中断
    - 一旦该锁被其他线程获取，如果我想获取，只能选择等待或者阻塞，直到其他线程释放该锁。如果其他线程永不释放该锁，那我只能永远等待下去
- 原理
  - 加锁和释放锁的原理：现象、时机、深入 JVM 看字节码：反编译、monitor 指令
    - 获取锁和释放锁的时机：内置锁
  - 可重入原理：加锁次数计数器
    - JVM 负责跟踪对象被加锁的次数
    - 线程第一次给对象加锁时，计数变为 1。每档这个相同的线程在此对象上再次获取锁时，计数会递增
    - 每当任务离开时，计数递减，当计数为 0 时，锁被完全释放
  - 保证可见性的原理：内存模型
- 缺陷
  - 效率低：锁的释放情况少、试图获取锁时不能设定超时、不能中断一个正在试图获取锁的线程
  - 不够灵活（读写锁更灵活）：加锁和释放锁的时机单一，每个锁紧有单一的条件（某个对象），可能是不够的
  - 无法知道是否成功获取到锁
- 面试题
  - 使用注意点：锁对象不能为空、作用域不宜过大、避免死锁
  - 如何选择 Lock 和 synchonized 关键字
- 思考题
  - 多个线程等待同一个 synchonized 锁时，JVM 如何选择下一个获取锁的是哪一个线程？
  - synchonized 使得同时只有一个线程可以执行，性能较差，有什么办法提升性能？
  - 怎么更灵活的控制锁的获取和释放（现在释放锁的时机都被规定死了），怎么办？
  - 什么是锁的升级、降级？什么是 JVM 里的偏向锁、轻量级锁、重量级锁？
- https://blog.csdn.net/asleepysheep/article/details/86440863

### 创建线程

- 两种方法的对比：Thread 的 run() 整个被重写、Runnable 最终调用 target.run()
- 创建线程只有一种方式：构造 Thead 类，而实现线程的执行单元有两种：
  - 1.实现 Runnable 接口的 run 方法，并把 Runnable 实例传给 Thread 类 
  - 2.重写 Thead 的 run 方法 (继承 Thead 类)
- start() 源码分析：
  - 1.启动新线程检查线程状态
  - 2.加入线程组
  - 3.调用 start0()

### 线程的正确启动

- start()
  - 启动新线程
  - 准备工作
  - 不能重复 start()
  - 源码分析
    - 启动新线程检查状态
    - 加入线程组
    - 调用 start0()
- 面试题
  - 一个线程两次调用 start() 会出现什么情况？为什么？
    - Java 的线程是不允许启动两次的，第二次调用必然会抛出 IllegalThreadStateException，这是一种运行时异常，多次调用 start 被认为是编程错误
  - 既然 start() 会调用 run()，为什么我们选择调用 start()，而不是直接调用 run() 呢？
    - 当你调用 start() 方法时，它会新建一个线程然后执行 run() 方法中的代码。如果直接调用 run() 方法，不会创建新线程也不会执行调用线程的代码，方法中的代码会在主线程中执行

### 线程的正确停止

- interrupt
- 实际开发中的两种最佳实践
  - 优先选择：传递中断
  - 不想或无法传递：恢复中断
  - 不应屏蔽中断
- 线程的错误停止方法
  - 被弃用的 stop，suspend 和 resume 方法
  - 用 volatile 设置 boolean 标记位
- 判断是否已被中断的相关方法
  - static boolean interrupted()
  - boolean isInterrupted()
  - Thread.interrupted()的目的对象
- 如何停止线程
  - https://blog.csdn.net/qq_35427139/article/details/99638129
  - 原理：用 interrupt 来请求、好处
  - 想停止线程，要请求方、被停止方、子方法被调用方相互配合
  - 最后再说错误的方法：stop/suspend 已废弃，volatile 设置 boolean 标记位无法处理长时间阻塞的情况

### 线程的生命周期

### Thread 和 Object 类中的重要方法详解

- Object 的 wait/notify/notifyAll 方法
  - 阻塞阶段
    - 直到以下 4 中情况之一发生时，才会被唤醒
      - 另一个线程调用这个对象的 notify() 且刚好被唤醒的是本线程
      - 另一个线程调用这个对象的 notifyAll()
      - 过了 wait(long timeout) 规定的超时时间，如果传入 0 就是永久等待
      - 线程自身调用了 interrupt()
  - 唤醒阶段
  - 遇到中断
- wait、notify、notifyAll特点、性质
  - 用必须先拥有 monitor
  - 只能唤醒其中一个
  - 属于 Object 类
  - 类似功能得 Condition
  - 同时持有多个锁的情况
- wait、notify、notifyAll 常见面试题
  - 用程序实现两个线程交替打印 0~100 的奇偶数
  - 手写生产者消费者模式
  - 为什么 wait() 需要在同步代码块内使用，而 sleep () 不需要
    - <https://blog.csdn.net/weixin_33857679/article/details/86033371> 
  - 为什么线程通信的方法 wait()，notify() 和 notifyAll() 被定义在 Object 类里？而 sleep 定义在 Thread 类里？
    - <https://blog.csdn.net/zfy163520/article/details/104947177> 
  - wait 方法是属于 Object 的，那调用 Thread.wait 会怎样？
  - 如何选择用 notify 还是 notifyAll？
    - <https://blog.csdn.net/u014658905/article/details/81035870> 
  - notifyAll 之后所有的线程都会再次抢夺锁，如果某线程抢夺失败怎么办？
    - <https://blog.csdn.net/qq_35427139/article/details/102491464> 
  - 用 suspend() 和 resume() 来阻塞线程可以吗？为什么？
- sleep 方法详解

  - 作用
    - 我只想线程在预期的时间执行，其他时候不要占用 CPU 资源
  - 特点
    - 不释放锁
      - 包括 synchronized 和 lock
      - 和 wait 不同
  - 响应中断
    - 抛出 InterruptedException
    - 清除中断状态
    - 优雅写法
      - TimeUnit.SECONDS.sleep()
  - 总结
    - sleep 方法可以让线程进入 Waiting 状态，并且不占用 CPU 资源，但是不释放锁，直到规定时间后再执行，休眠期间如果被中断，会抛出异常并清除中断状态
- join 方法
  - 作用：
    - 因为新的线程加入了我们，所以我们要等它执行完再出发
  - 用法：
    - main 等待 thread1 执行完毕，注意谁等谁
  - join 期间，线程是 Waiting 状态
- yield 方法
  - 作用：
    - 释放我的 CPU 时间片
  - 定位：JVM 不保证遵循
  - yield 和 sleep 区别：是否随时可能再次被调度
#### 常见面试题
  - wait/notify、sleep 异同（方法属于哪个对象？线程状态怎么切换？）
    - 相同
      - 阻塞
      - 响应中断
    - 不同
      - 同步方法中
      - 释放锁
      - 指定时间
      - 所属类


### 线程的各个属性

#### 常见面试问题

- 什么时候我们需要设置守护线程？
  - 通常不用设置
- 如何应用线程优先级来帮助程序运行？有哪些禁忌？
  - 不应该用优先级来帮助程序运行，因为不同的操作系统对于优先级的映射及调度都不一样
- 不同的操作系统如何处理优先级问题？
- 守护线程和普通线程的区别
- 是否需要给线程设置为守护线程

#### 线程各属性纵览

- 编号（ID）
  - 每个线程有自己的 ID，用于标识不同的线程
  - 被后续创建的线程使用，唯一性，不允许被修改
- 名称（Name）
  - 作用让用户和程序员在开发、调试或运行过程中，更容易区分每个不同的线程、定位问题等
- 是否是守护线程（isDaemon）
  - true 代表该线程是【守护线程】，false 代表线程是非守护线程，也就是【用户线程】
  - 守护线程作用：给用户线程提供服务
  - 守护线程的 3 个特性
    - 线程类型默认继承自父线程
    - 被谁启动
    - 不影响 JVM 退出
- 优先级（Priority）
  - 优先级这个属性的目的是告诉线程调度器，用户希望哪些线程相对多运行、哪些少运行
  - 10 个级别，默认为 5
  - 程序设计不应依赖于优先级
    - 不同操作系统不一样
    - 优先级会被操作系统改变

### 未捕获异常如何处理

- 为什么需要 UncaughtExceptionHandler
  - 主线程可以轻松发现异常，子线程却不行
  - 子线程异常无法用传统方法捕获
  - 不能直接捕获的后果、提高健壮性
- 线程的未捕获异常 UncaughtException 应该如何处理
  - 不推荐：手动在每个 run 方法里进行 try catch
  - 推荐：利用 UncaughtExceptionHandler
#### 常见面试问题
- Java 异常体系
- 如何处理全局异常？为什么要全局处理？不处理行不行？
- run 方法是否可以抛出异常？如果抛出异常，线程的状态会怎么样？
  - 不可以；线程会终止运行，打印出异常堆栈信息
- 线程中如何处理某个未处理异常？
  - 利用 UncaughtExceptionHandler 进行全局处理
### 双刃剑：多线程导致的问题

- 运行结果错误：a++ 多线程下出现消失的请求现象
- 活跃性问题：死锁、活锁、饥饿
- 对象发布和初始化的时候的安全问题
  - 什么是发布
    - 声明为 public
    - return 一个对象
    - 把类作为参数传递到其他类的方法中
  - 什么是逸出
    - 方法返回一个 private 对象（private 本意是不让外部访问）
    - 还没完成初始化（构造函数没完全执行完毕）就把对象提供给外界，比如：
      - 在构造函数中未初始化完毕就 this 赋值
      - 隐式逸出 --- 注册监听事件
      - 构造函数中运行线程
  - 如何解决逸出
    - 返回 "副本"
    - 工厂模式
- 各种需要考虑线程安全的情景
  - 访问共享的变量和资源，会有并发风险，比如对象的属性、静态变量、共享缓存、数据库等
  - 所有依赖时序的操作，即使每一步操作都是线程安全的，还是存在并发问题：read-modify-write（一个线程读取了一个共享数据，并在此基础上更新该数据）、check-then-act（一个线程读取了一个共享数据，并在此基础上决定其下一步的操作）
  - 不同的数据之间存在捆绑关系的时候
  - 我们使用其他类的时候，如果对方没有声明自己是线程安全的：hashmap
- 为什么多线程会带来性能问题
  - 调度：上下文切换
    - 什么是上下文
      - 保存现场
      - 上下文切换可认为是内核（操作系统的核心）在 CPU 上对于进程进行以下的活动：1.挂起一个进程，将这个进程在 CPU 中的状态存储于内存的某处 2.在内存中检索下一个进程的上下文并将其在 CPU 的寄存器中恢复 3.跳转到程序计数器所指向的位置（即跳转到进程被中断时的代码行），以恢复该进程
    - 缓存开销
      - 缓存失效（CPU 重新缓存）
    - 何时会导致密集的上下文切换：频繁抢锁、IO 读写等原因导致频繁阻塞
  - 协作：内存同步
    - Java 内存模型（为了数据的正确性，同步手段往往会使用禁止编译器优化、使 CPU 内的缓存失效）

### 线程核心基础面试题

- 有几种实现线程的方法？思路有 5 点
  - 实现 Runnable 接口，重写 run()，运行 start()
  - 继承 Thread 类，重写 run()，运行 start()
- 实现 Runnable 接口和继承 Thread 类哪种方式更好？
  - 实现 Runnable 接口更好（最终调用 target.run()），而继承 Thread 类则是整个 run 方法被重写
- 一个线程两次调用 start() 会出现什么情况？为什么？
- 既然 start() 会调用 run() 方法，为什么我们选择用 start()，而不是直接调用 run()？
- 如何停止线程
- 如何处理不可中断的阻塞
- 线程有哪几种状态？生命周期是什么？
- 用程序实现两个线程交替打印 0~100 的奇偶数
- 手写生产者消费者设计模式
- 为什么 wait() 需要在同步代码块内使用，而sleep() 不需要
- 为什么线程通信的方法 wait()，notify() 和 notifyAll() 被定义在 Object 类里？而 sleep() 定义在 Thread 类里？
- wait 方法是属于 Object 对象的，那调用 Thread.wait 会怎样？
- 如何选择用 notify 还是 notifyAll？
- notifyAll 之后所有的线程都会再次抢夺锁，如果某线程抢夺失败怎么办？
- 用 suspend() 和 resume() 来阻塞线程可以吗？为什么？
- wait/notify、sleep 异同点（方法属于哪个对象？线程状态怎么切换？）
- 在 join 期间，线程处于哪种线程状态？
- 守护线程和普通线程的区别
- 我们是否需要给线程设置为守护线程？
- run 方法是否可以抛出异常？如果抛出异常，线程的状态会怎样？
- 线程中如何处理某个未处理异常？
- 什么是多线程的上下文切换？

### Java 内存模型 --- 底层原理

- JVM 内存结构：与 Java 虚拟机得运行时区域有关

- Java 内存模型：与 Java 并发编程有关

  - 为什么需要 JMM
    - C 语言不存在内存模型得概念
    - 依赖处理器，不同处理器结果不一样
    - 无法保证并发安全
    - 需要一个标准，让多线程运行的结果可预期
  - JMM 是规范
    - 是一组规范，需要各个 JVM 的实现来遵守 JMM 规范，以便于开发者可以利用这些规范，更方便地开发多线程程序
    - 如果没有这样的 JMM ·内存模型来规范，那么很可能经过了不同JVM 的不同规则的重排序之后，导致不同的虚拟机上运行的结果不一样
  - JMM 是工具类和关键字的原理
    - volatile、synchronized、Lock等的原理都是 JMM
    - 如果没有 JMM，那就需要我们自己指定什么时候用内存栅栏等，那是相当麻烦的，幸好有了 JMM，让我们只需要用同步工具和关键字就可以开发并发程序

- 最重要的 3 点内容：重排序、可见性、原子性

  - 重排序
    - 在线程 1 内部的两行代码的实际执行顺序和代码在 Java 文件中的顺序不一致，代码指令并不是严格按照代码语句顺序执行的，它们的顺序被改变了
    - 好处
      - 提高处理速度
    - 重排序的 3 种情况
      - 编译器优化：包括 JVM、JIT 编译器等
      - CPU 指令重排：就算编译器不发生重排，CPU 也可能对指令进行重排
      - 内存的 "重排序"：线程 A 的修改线程 B 却看不到，引出可见性问题
  - 为什么会有可见性问题
    - CPU 有多级缓存，导致读的数据过期
      - 如果所有的核心都只用一个缓存，那么也就不存在内存可见性问题
      - 每个核心都会将自己需要的数据读到独占缓存中，数据修改后也是写入到缓存中，然后等待刷入到主存中。所以会导致有些核心读的值是一个过期的值
  - 主内存和本地内存
    - 本地内存：是 JMM 的一个抽象，是对于寄存器、一级缓存、二级缓存等的抽象
    - 主内存和本地内存的关系
      - 所有的变量都存储在主内存中，同时每个线程也有自己独立的工作内存，工作内存中的变量内容是主内存中的拷贝
      - 线程不能直接读写主内存的变量，而是只能操作自己工作内存中的变量，然后再同步到主内存中
      - 主内存是多个线程共享的，但线程间不共享工作内存，如果线程间需要通信，必须借助主内存中转来完成
      - 所有的共享变量存在于主内存中，每个线程有自己的本地内存，而且线程读写共享数据也是通过本地内存交换的，所以导致了可见性问题
  - Happens-Before 规则有哪些
    - 单线程规则
    - 锁操作（synchronized 和 Lock）
    - volatile 变量
    - 线程启动
    - 线程 join
    - 传递性：如果hb(A, B) 而且 hb(B, C)，那么可以推出hb(A, c)
    - 中断：一个线程被其他线程 interrupt 时，那么检测中断(isInterrupted) 或者抛出 InterruptedException 一定能看到
    - 构造方法：对象构造方法的最后一行指令 happens-before 于 finalize() 的第一行指令
    - 工具类的 Happens-Before 原则
      - 线程安全的容器 get 一定能看到在此之前的 put 等存入动作
      - CountDownLatch
      - Semaphore
      - Future
      - 线程池
      - CyclicBarrier
  - volatile 关键字
    - volatile 是一种同步机制，比 synchronized 或者 Lock 相关类更轻量，因为使用 volatile 并不会发生上下文切换等开销很大的行为
    - 如果一个变量被修饰成 volatile，那么 JVM 就知道了该变量可能会被并发修改
    - 但是开销小，相应的能力也小，虽然说 volatile 是用来同步的保证线程安全的，但是 volatile 做不到 synchronized 那样的原子保护，volatile 仅在很有限的场景下才能发挥作用
    - volatile 的适用场合
      - 不适用：a++
      - 适用场合 1：boolean flag，如果一个共享变量自始自终只被各个线程赋值，而没有其他操作，那么就可以用 volatile 来代替 synchronized 或者代替原子变量，因为赋值自身是有原子性的，而 volatile 又保证了可见性，所以就足以保证线程安全
      - 适用场合 2：作为刷新之前变量的触发器
    - volatile 的两点作用
      - 可见性：读一个 volatile 变量之前，需要先使相应的本地缓存失效，这样就必须到主内存读取最新值，写一个 volatile 属性会立即刷入到主内存
      - 禁止指令重排序优化：解决单例双重锁乱序问题
        - 1.分配内存空间
        - 2.初始化对象
        - 3.将内存空间的地址赋值给对应的引用
    - volatile 和 synchronized 的关系
      - volatile 在这方面可以看作是轻量版的 synchronized：如果一个共享变量自始自终只被各个线程赋值，而没有其他操作，那么就可以用 volatile 来代替 synchronized 或者代替原子变量，因为赋值自身是有原子性的，而 volatile 又保证了可见性，所以就足以保证线程安全
    - volatile 小结
      - volatile 修饰符适用于以下场景：某个属性被多个线程共享，其中有一个线程修改了此属性，其他线程可以立即得到修改后的值，比如 boolean flag；或者作为触发器，实现轻量级同步
      - volatile 属性的读写操作都是无锁的，它不能代替 synchronized，因为它没有提供原子性和互斥性。因为无锁，不需要花费时间在获取锁和释放锁上，所以它是低成本的
      - volatile 只能作用于属性，用 volatile 修饰属性，这样 compilers 就不会对该属性进行指令重排序
      - volatile 提供了可见性，任何一个线程对其的修改将立马对其他线程可见，volatile 属性不会被线程缓存，始终从主存中读取
      - volatile 提供了 happens-before 保证，对 volatile 变量 v 的写入 happens-before 所有其他线程后续对 v 的读操作
      - volatile 可以使 long 和 double 的赋值是原子的
  - 能保证可见性的措施
    - 除了 volatile 可以让变量保证可见性外，synchronized、Lock、并发集合、Thread.join() 和 Thread.start() 等都可以保证可见性
  - 升华：对 synchronized 可见性的正确理解
    - synchronized 不仅保证了原子性，还保证了可见性
  - 什么是原子性
    - 一系列的操作，要么全部执行成功，要么全部不执行，不会出现执行一般的情况，是不可分割的
    - 除 long 和 double 之外的基本类型（int、byte、boolean、short、char、float）的赋值操作
    - 所有引用 reference 的赋值操作，不管是 32 位的机器还是 64 的机器
    - Java.concurrent.Atomic.* 包中所有类的原子操作
    - 对于 64 位的值的写入，可以分为两个 32 位的操作进行写入、读取错误、使用 volatile 解决
    - 结论：在 32 位的 JVM 上，long 和 double 的操作不是原子的，但是在 64 位的 JVM 是原子的
    - 原子操作 + 原子操作  != 原子操作
  - 面试常见问题
    - 单例模式 8 种写法、单例和并发的关系
      - 为什么使用单例模式
        - 节省内存和计算、保证结果正确、方便管理
      - 单例模式适用场景
        - 无状态的工具类：比如日志工具类，不管是在哪里使用，我们需要的只是它帮我们记录日志信息，除此之外，并不需要在它的实例对象上存储任何状态，这时陪我们只需要一个实例对象即可
        - 全局信息类：比如我们在一个类上记录网站的访问次数，我们不希望有的访问被记录在对象 A 上，有的记录在对象 B 上，这时我们就让这个类为单例
      - 8 种写法
        - 饿汉式（静态常量）【可用】
        - 饿汉式（静态代码块）【可用】
        - 懒汉式（线程不安全）【不可用】
        - 懒汉式（线程不安全，同步代码块）【不可用】
        - 懒汉式（线程安全，同步方法）【不推荐使用】
        - 双重检查【推荐面试使用】
          - 线程安全、延迟加载、效率较高
          - 为什么要用 volatile
            - 新建对象实际上有 3 个步骤
            - 重排序会带来 NPE
            - 防止重排序
        - 静态内部类【推荐用】
        - 枚举【推荐代码中使用：最好的方法，还可以防止反序列化重新创建新的对象】
    - 生成对象的过程不是原子操作
      - 新建一个空的 Person 对象
      - 把这个对象的地址指向 p
      - 执行 Person 的构造函数
    - volatile 和 synchronized 的异同
    - 什么是 Java 内存模型
    - 什么是原子操作？Java 中有哪些原子操作
    - 什么是内存可见性
    - 64 位的 double 和 long 写入时是原子的吗

- Java 对象模型：与 Java 对象在虚拟机中的表现形式有关

### 线程安全
#### 互斥同步
- 为什么需要 Lock
	- synchronized 不够用
		- 效率低：锁释放情况少、试图获取锁时不能设定超时、不能中断一个正在试图获取锁的线程
		- 不够灵活（读写锁更灵活）：加锁和释放锁的时机单一，每个锁仅有单一的条件（某个对象），可能是不够的
		- 无法知道是否成功获取到锁 	
- Lock 主要方法
	- lock()
		- lock() 就是最普通的获取锁。如果锁已经被其他线程获取，则进行等待
		- Lock 不会像 synchronized 一样在异常时自动释放锁
		- 最佳实践：在 finally 中释放锁，以保证发生异常时锁一定被释放
		- lock() 不能被中断，这会带来很大的隐患：一旦陷入死锁，lock() 就会陷入永久等待
	- tryLock()
		- 尝试获取锁，如果当前锁没有被其他线程占用，则获取成功，返回 true，否则返回 false，代表获取锁失败
		- 该方法会立即返回，即便拿不到锁也不会一直等待
		- 相比于 lock()，trylock() 可以根据是否能获取锁来决定后续程序的行为
	- tryLock(long time, TimeUnit unit)
		- 超时就放弃
	- lockInterruptibly() 
		- 相当于 trylock(long time, TimeUnit unit) 把超时时间设置为无限。在等待锁的过程中，线程可以被中断
	- unlock()
		- 解锁 在 finally 里执行
- 可见性保证
	- Lock 的加解锁和 synchronized 有同样的内存语义，也就是说，下一个线程加锁后可以看到所有前一个线程解锁前发生的所有操作
#### 锁的分类
- 线程要不要锁住同步资源
	- 锁住：悲观锁：为了确保结果的正确性，会在每次获取并修改数据时把数据锁住，让别人无法访问该数据，这样就可以确保数据内容万无一失
		- synchronized 和 Lock 相关类
		- 互斥同步锁（悲观锁）劣势
			- 阻塞和唤醒带来的性能劣势
			- 永久阻塞：如果持有锁的线程被永久阻塞，比如遇到了无限循环、死锁等活跃性问题，那么等待该线程释放锁的那几个悲催的线程将永远得不到执行
			- 优先级反转
		- select for update 就是悲观锁
	- 不锁住：乐观锁：认为自己在处理操作的时候不会有其他线程来干扰，所以并不会锁住被操作对象，在更新的时候，去对比在我修改的期间数据有没有被其他人改变过：如果没被修改过，就说明真的只有自己在操作，那我就正常修改数据，如果被修改过，就不能继续刚才的更新数据过程了，会选择放弃、报错、重试等策略。乐观锁的实现一半都是利用 CAS 算法实现的
		- 原子类、并发容器等
		- Git 乐观锁的典型例子
		- 用 version控制数据库就是乐观锁
	- 乐观锁与悲观锁的使用场景
		- 悲观锁：适用于并发写入多的情况，适用于临界区持锁时间比较长的情况，悲观锁可以避免大量的无用自旋等消耗，典型情况：
			- 临界区有 IO 操作
			- 临界区代码复杂或者循环量大
			- 临界区竞争非常激烈
		- 乐观锁：适合并发写入少，大部分是读取的场景，不加锁能让读取性能大幅提高
	- 乐观锁与悲观锁的开销对比
		- 悲观锁的原始开销要高于乐观锁，但是特点是一劳永逸，临界区持锁时间就算越来越差，也不会对互斥锁的开销造成影响
		- 乐观锁一开始的开销被悲观锁小，但是如果自旋时间很长或者不断重试，那么消耗的资源也会越来越多
- 多线程能否共享一把锁
	- 共享锁和排它锁的典型就是读写锁 ReentrantReadWriteLock，其中读锁是共享锁，写锁是独享锁
		- 读写锁的规则
			- 多个线程只申请读锁，都可以申请到
			- 如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁
			- 如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或者读锁，则申请的线程会一直等待释放写锁
			- 一句话总结：要么是一个或者多个线程同事拥有读锁，要么是一个线程有写锁，但是两者不会同时出现（要么多读，要么一写）

		- 读锁插队策略
			- 公平锁：不允许插队
			- 非公平锁：写锁可以随时插队（避免饥饿）、读锁仅在等待队列头结点不是想获取写锁的线程时可以插队
		- 升降级策略
			- 只能降级，不能升级（升级造成死锁）
	- 可以：共享锁
		- 共享锁又称为读锁，获得共享锁之后，可以查看但无法修改和删除数据，其他线程此时也可以获取到共享锁，也可以查看但无法修改和删除数据
	- 不可以：独占锁
- 多线程竞争时是否排队
	- ReentrantLock
	- 排队：公平锁
		- 优势：各线程公平平等，每个线程在等待一段时间后，总有执行的机会
		- 劣势：更慢，吞吐量更小
	- 先尝试插队，插队失败再排队：非公平锁
		- 优势：更快，吞吐量更大
		- 劣势：有可能产生线程饥饿，也就是某些线程在长时间内始终得不到执行
	- 公平与非公平
		- 公平是指按照线程请求的顺序来分配锁；非公平指的是不完全按照请求的顺序，在一定情况下可以插队
		- 注意：非公平也同样提倡 "插队" 行为，这里的非公平指的是 "在合适的时机" 插队，而不是盲目插队

	- 为什么要有非公平锁
		- 为了提高效率，避免唤醒带来的空档期
- 同一个线程是否可以重复获取同一把锁
	- 可以：可重入锁
		- ReentrantLock
		- 可重入锁的好处
			- 避免死锁
			- 提升封装性
	- 不可以：不可重入锁
- 是否可以中断
	- 可以：可中断锁：如果一个线程 A 正在执行锁中的代码，另一个线程 B 正在等待该锁，可能由于等待时间过长，线程 B 不想等待了，想处理其他事情，我们可以中断它
		- Lock 是可中断锁，因为 tryLock(time) 和 lockInterruptibly 都能响应中断
	- 不可以：非可中断锁
		- synchronized 不可中断锁
- 等锁的过程
   - 自旋：自旋锁
  	- 为了让当前线程 "稍等一下"，我们需要让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而逝直接获取同步资源，从而避免切换线程的开销
        	 - 自旋锁的缺点
            		- 如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源
                		- 在自旋的过程中，一直消耗 CPU，所以虽然自旋的起始开销低于悲观锁，但是随着自旋时间的增长，开销也是线性增长的
                	 - 自旋锁的适用场景
                  		- 一般用于多核的服务器，在并发不是特别高的情况下，比阻塞锁的效率高
                    		- 适用于临界区比较短小的情况，否则如果临界区很大（线程一旦拿到锁，很久才释放），那也是不合适的
                         	 - AtomicInteger 的实现：自旋锁的实现原理是 CAS
                                   		- AtomicInteger 中调用 unsafe 进行自增操作的源码中的 do-while 循环就是一个自旋操作，如果修改过程中遇到其他线程竞争失败导致没修改成功，就在 while 里死循环，直至修改成功
   - 阻塞：非自旋锁
  	- 如果没有拿到锁，会直接把线程阻塞，直到被唤醒

#### 锁优化
- Java 虚拟机对锁的优化
	- 自旋锁和自适应
	- 锁消除
	- 锁粗化
- Java 开发对锁的优化
	- 缩小同步代码块
	- 尽量不要锁住方法
	- 减少请求锁的次数
	- 避免人为制造 "热点"
	- 锁中尽量不要再包含锁
	- 选择合适的锁类型和合适的工具类
#### 非互斥同步
- Atomic
  - 什么是原子类
    - 不可分割
    - 一个操作是不可中断的，即便是多线程的情况下也可以保证
    - java.util.concurrent.atomic
  - 原子类有什么作用
    - 作用和锁类似，是为了保证并发情况下线程安全。不过原子类相比于锁，有一定的优势：
      - 粒度更细：原子变量可以把竞争范围缩小到变量级别，这是我们可以获得的最细粒度的情况，通常锁的粒度都要大于原子变量的粒度
      - 效率更高：通常，使用原子类的效率会比使用锁的效率更高，除了高度竞争的情况
  - Atomic* 基本类型原子类
    - AtomicInteger
      - AtomicInteger 加载 Unsafe 工具，用来直接操作内存数据
      - 用 Unsafe 来实现底层操作
      - 用 volatile 修饰 value 字段，保证可见性
      - getAndAddInt 方法分析
      - public final int get() // 获取当前的值
      - public final int getAndSet(int newValue) // 获取当前的值并设置新的值
      - public final int getAndIncrement() // 获取当前的值并自增
      - public final int getAndDecrement() // 获取当前的值并自减
      - public final int getAndAdd(int deita) // 获取当前的值并加上预期的值
      - boolean compareAndSet(int expect, int update) // 如果当前的数值等于预期值，则以原子方式将该值设置为输入值 (update)
    - AtomicLong
    - AtomicBoolean
  - Atomic*Array 数组类型原子类
    - AtomicIntegerArray
    - AtomicLongArray
    - AtomicReferenceArray
  - Atomic*Reference 引用类型原子类
    - AtomicReference
      - 可以让一个对象保证原子性，功能比 AtomicInteger 更强，因为一个对象可以包含很多属性
    - AtomicStampedReference
      - 引用类型原子类的升级，带时间戳，可以解决 ABA 问题
    - AtomicMarkableReference
  - Atomic*FieldUpdater 升级类型原子类
    - AtomicIntegerFieldUpdater
      - 原子更新整型字段的更新器
      - 对普通变量进行升级
      - 注意：可见范围、不支持 static
    - AtomicLongFieldUpdater
    - AtomicReferenceFieldUpdater
  - Adder 累加器
    - LongAdder
      - 高并发下 LongAdder 比 AtomicLong 效率高，不过本质是空间换时间
        - AtomicLong 实现原理是每一次加法都需要做同步（flush 和 reflush），所以在高并发的时候会导致冲突比较多，也就降低了效率
        - LongAdder  每个线程都有自己的一个计数器，仅用来在自己线程内计数，这样就不会和其他线程的计数器干扰
      - 竞争激烈的时候，LongAdder 把不同线程对应到不同的 Cell 上进行修改，降低了冲突的概率，是多段锁的理念，提高了并发性
      - LongAdder 引入了分段累加的概念，内部有一个 base 变量和一个 Cell[] 数组共同参与计数：
        - base 变量：竞争不激烈，直接累加到该变量上
        - Cell[] 数组：竞争激烈，各个线程分撒累加到自己的槽 Cell[i] 中
      - 对比 AtomicLong 和 LongAdder
        - 在低竞争的情况下，AtomicLong 和 LongAdder 具有相似的特征。但在竞争激烈的情况下，LongAdder 的预期吞吐量要高很多，但要消耗更多空间
        - LongAdder 适合的场景是统计求和计数的场景，而且 LongAdder 基本只提供了 add 方法，而 AtomicLong 还具有 cas 方法
    - DoubleAdder
  - Accumulator 累加器
    - LongAccumulator
    - DoubleAccumulator

#### 并发容器

  - ArrayList 和 HashMap 可以使用Collections.synchronizedList(new ArrayList<E>()) 和 Collections.synchronizedMap(new HashMap<K, V>()) 变成线程安全的
  - ConcurrentHashMap：线程安全的 HashMap
    - Java 7 中的 ConcurrentHashMap 最外层是多个 segment，每个 segment 的底层数据结构与 HashMap 类似。仍然是数组和链表组成的拉链法
    - 每个 segment 独立上 ReentrantLock 锁。每个 segment 之间互不影响，提高了并发效率
    - ConcurrentHashMap 默认有 16 个 Segments，所以最多可以同时支持 16 个线程并发写（操作分别分布在不同的 Segment 上）这个默认值在初始化的时候设置为其他值，但是一旦初始化后，是不可以扩容的
  - ConcurrentHashMap jdk 1.7 与 jdk 1.8 的区别
    - 数据结构
      - 1.7：数组加链表
      - 1.8：数组加链表加红黑树
    - Hash 碰撞
      - 1.7：拉链法
      - 1.8：拉链法，当链表长度大于 8 转为红黑树
    - 保证并发安全
      - 1.7：分段锁
      - 1.8：synchronized + CAS
    - 查询复杂度
      - 1.7：O(n)
      - 1.8：O(logn)
    - 为什么链表长度超过 8 要转为红黑树
      - 泊松分布，链表长度大于 8 的概率是千万分之一，所以大于 8 时转为红黑树也可以保证查询效率
    - putVal 流程
      - 判断 key value 不为空
      - 计算 hash 值
      - 根据对应位置节点的类型来赋值，或者 helpTransfer，或者增长链表，或者给红黑树增加节点
      - 检查满足阈值就 "红黑树化"
      - 返回 oldVal
    - get 流程
      - 计算 hash 值
        - 找到对应的位置，根据情况进行：
        - 直接取值
        - 红黑树里找值
        - 遍历链表取值
        - 返回找到的结果
    - 组合操作
      - replace
      - putIfAbsent
        - if (!map.containsKey(key)) return map.put(key, value); else return map.get(key);
  - HashMap
    - 红黑树
      - 对二叉查找树 BST 的一种平衡策略，O(logN) vs O(N)
      - 会自动平衡，防止极端不平衡从而影响查找效率的情况发生
    - 线程不安全的
      - 同时 put 碰撞导致数据丢失
      - 同时 put 扩容导致数据丢失
      - 死循环造成的 CPU 100%（仅在 jdk7 及以前存在）
  - CopyOnWriteArrayList：线程安全的 List
    - 读操作可以尽可能地快，而写即使慢一些也没太大关系
    - 读多写少：黑名单，每日更新；监听器：迭代操作远多于修改操作
    - 读写规则
      - 读写锁规则的升级：读取是完全不用加锁的，写入也不会阻塞读取操作。只有写入和写入之间需要同步等待
    - 实现原理
      - 创建新副本、读写分离
      - "不可变" 原理
      - 迭代的时候
    - 缺点
      - 数据一致性问题：CopyOnWrite 容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果希望写入的数据可以实时读取，请不要使用 CopyOnWrite 容器
      - 内存占用问题：CopyOnWrite 的写是复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存
  - 为什么使用队列
    - 用队列可以在线程间传递数据：生产者消费者模式、银行转账
    - 考虑锁等线程安全问题的重任从 "你" 转移到了 "队列" 上
  - BlockingQueue：接口，表示阻塞队列，非常适合用于作为数据共享的通道
    - 阻塞队列是具有阻塞功能的队列
    - 通常阻塞队列的一端给生产者放数据用，另一端给消费者拿数据用。阻塞队列是线程安全的，所以生产者和消费者都可以是多线程的
    - take()：获取并移除队列的头结点，一旦如果执行 take 的时候，队列里无数据，则阻塞知道队列里有数据
    - put()：插入元素。但是如果队列已满，那么就无法继续插入，则阻塞，直到队列里有空闲空间
    - 是否有界（容量有多大）：无界队列意味着可以容纳非常多（Integer.MAX_VALUE，约为 2 的 31 次，可近似认为是无限容量）
    - 阻塞队列是线程池的重要组成部分
  - ArrayBlockingQueue
    - 有界
    - 指定容量
    - 公平：可以指定是否需要保证公平，如果想保证公平的话，那么等待了最长时间的线程会被优先处理，同时这样会带来一定的性能消耗
  - LinkedBlockingQueue
    - 无界
    - 容量 Integer.MAX_VALUE
    - 内部结构：Node、两把锁。分析 put 方法
  - PriorityBlockingQueue
    - 支持优先级
    - 自然顺序（而不是先进先出）
    - 无界队列
    - PriorityQueue 的线程安全版本
  - SynchronousQueue
    - 容量为 0
    - SynchronousQueue 的容量不是 1而是 0，因为 SynchronousQueue 不需要去持有元素，它所做的就是直接传递（direct handoff）
    - SynchronousQueue 没有 peek 函数，因为 peek 是取出头结点，但是 SynchronousQueue 的容量是 0，所以连头结点都没有，也就没有 peek 方法。同理也没有 iterate 相关方法
    - 是一个极好的用来直接传递的并发数据结构
    - SynchronousQueue 是线程池 Executors.newCachedThreadPool() 使用的阻塞队列
  - DelayQueue
    - 延迟队列，根据延迟时间排序
    - 元素需要实现 Delayed 接口，规定排序规则
  - ConcurrentLinkedQueue：高效的非阻塞并发队列，使用链表实现。可以看作一个线程安全的 LinkedList
    - 使用 CAS 非阻塞算法实现线程安全（不具备阻塞功能），适用于对性能要求较高的并发场景
    - 看源码的 offer 方法的 CAS 思想，内有 p.casNext 方法，用了 UNSAFE.compareAndSwapObject
  - ConcurrentSkipListMap：一个 Map，使用跳表的数据结构进行快速查找
  - 并发容器总结
    - java.util.concurrent 包提供的容器，分为 3 类：Concurrent *、CopyOnWrite *、Blocking *
    - Concurrent* 的特点是大部分通过 CAS 实现并发，而 CopyOnWrite* 则是通过复制一份数据来实现的，Blocking* 通过 AQS 实现的

#### CAS

  - 适用场景：并发
  - CPU 的特殊指令
  - 我认为 V 的值应该是 A，如果是的话那我就把它改成 B，如果不是 A（说明被别人修改过了），那我就不修改了，避免多人同时修改导致出错
  - CAS 有三个操作数：内存值 V、预期值 A、要修改的值 B，当且仅当预期值 A 和内存值 V 相同时，才将内存值修改为 B，否则什么都不做。最后返回现在的 V 值
  - CAS 的缺点
    - ABA 问题
    - 自旋时间过长
  - Java 如何利用 CAS 实现原子操作的
    - Unsafe 类中的 compareAndSwapInt 方法
      - 先拿到变量 value 在内存中的地址
      - 通过 Atomic::cmpxchg 实现原子性的比较和替换，其中参数 x 是即将更新的值，参数 e 是原内存的值。至此，最终完成了 CAS 的全过程

#### Unsafe 类

  - Unsafe 是 CAS 的核心类。Java 无法直接访问底层操作系统，而是通过本地（native）方法来访问。JDK 提供了一个 Unsafe 类。它提供了硬件级别的原子操作
  - valueOffset 表示的是变量值在内存中的编译地址，因为 Unsafe 就是根据内存偏移地址获取数据的原值的，这样就可以通过 unsafe 实现 CAS
#### 无同步、不可变

- 不变性

  - 如果对象在被创建后，状态就不能被修改，那么它就是不可变的
  - 具有不变性的对象一定是线程安全的
- final

  - 类防止被继承、方法防止被重写、变量防止被修改
  - 天生是线程安全的，而不需要额外的同步开销
  - final 修饰变量
    - 被 final 修饰的变量，意味着值不能被修改。如果变量是对象，那么对象的引用不能变，但是对象自身的内容依然可以变化

  - final 修饰变量：赋值时机
    - 属性被声明伟 final，该变量则只能被赋值一次。且一旦被赋值，final 变量就不能再被改变
    - 类中的 final 属性
      - 第一种是在声明变量的等号右边直接赋值
      - 第二种就是在构造函数中赋值
      - 第三种就是在类的初始代码块中赋值（不常用）
    - 类中的 static final 属性
      - 第一种是在声明变量的等号右边直接赋值
      - 可以用 static 初始代码块赋值，但是不能用普通的初始代码块赋值
    - 方法中的 final 变量
      - 由于变量是在方法里，所以没有构造函数，也不存在初始代码块
      - 不规定赋值时机，使用前必须赋值，和方法中的非 final 变量的要求是一样的
  - 为什么要规定赋值时机
    - 如果初始化不赋值，后续从 null 变成 你的赋值，违背了 final 的不变性原则
- final 的注意点
  - final 修饰方法
    - 构造方法不允许 final 修饰
    - 不可被重写，也就是不能被 override，即便是子类有同样名字的方法，那也不是 override，和 static 方法一样
    - 引申：static 方法不能被重写
  - final 修饰类
    - 不可被继承
  - final 修饰对象时，只是对象的引用不可变，而对象本身的属性是可以变化的
- 满足以下条件，对象不可变
  - 对象创建后，其状态就不能被修改
  - 所有属性都是 final 修饰的
  - 对象创建过程中没有发生逸出
- ThreadLocal
  - 两大使用场景
    - 每个线程需要一个独享的对象（通常是工具类，典型需要使用的类 SimpleDateFormat 和 Random）
      - 每个 Thread 内有自己的实例副本，不共享
      - 比喻：教材只有一本，一起做笔记有线程安全问题，复印后没问题
      - 在 ThreadLocal 第一次 get 时把对象初始化出来，对象的初始化时机可以有我们控制
    - 每个线程内需要保存全局变量（例如在拦截器中获取用户信息），可以让不同方法直接使用，避免参数传递的麻烦
      - 如果需要保存到 ThreadLocal 里的对象的生成时机不由我们随意控制，例如拦截器生成的用户信息，用 ThreadLocal.set 直接放到我们的 ThreadLocal 中去，一边后续使用
  - 两个作用
    - 让某个需要用到的对象在线程间隔离（每个线程都有自己的独立的对象）
    - 在任何方法中都可以轻松获取到该对象
  - 使用 ThreadLocal 的好处
    - 达到线程安全
    - 不需要加锁，提高执行效率
    - 更高效地利用内存、节省开销：相比于每个任务都新建一个 SimpleDateFormat，显然用 ThreadLocal 可以节省内存和开销
    - 免去传参的繁琐
  - ThreadLocal 原理
    - 每个 Thread 对象中都持有一个 ThreadLocalMap 成员变量，一个 ThreadLocalMap 存储多个 ThreadLocal
  - 主要方法介绍
    - T initialValue()：初始化
      - 该方法会返回当前线程对应的 "初始值"，这是一个延迟加载的方法，只有在调用 get 时才会触发
      - 当线程第一次使用 get 方法访问变量时，将调用此方法，除非线程先前调用了 set 方法，这种情况下，不会为线程调用此方法
      - 通常每个线程最多调用一次此方法，但如果已经调用了 remove() 后，再调用 get()，则可以再次调用此方法
      - 如果不重写本方法，这个方法会返回 null。一般使用匿名内部类的方法来重写 initialValue()，一边后续使用中可以初始化副本对象
    - void set(T t)：为这个线程设置一个新值
    - T get()：得到这个线程对应的 value。如果是首次调用get()，则会调用 initialize 来得到这个值
      - 先取出当前线程的 ThreadLocalMap，然后调用map.getEntry() 方法，把本 TheadLocal 的引用作为参数传入，取出 map 中属于本 ThreadLocal 的value
      - 注意：这个 map 以及 map 中的 key 和 value 都是保存在线程中的，而不是保存在 ThreadLocal 中
    - void remove()：删除对应这个线程的值
    - ThreadLocalMap 类
      - 也就是 Thread.threadLocals
      - ThreadLocalMap 类是每个线程 Thread 类里面的变量，里面最重要的是一个键值对数组 Entry[] table，可以认为是一个 map，键值对：
        - 键：这个 ThreadLocal
        - 值：时机需要的成员变量，比如 user 或者 simpleDateFormat 对象
    - ThreadLocalMap 解决冲突
      - 采用线性探测法，也就是如果发生冲突，就继续找下一个空位置，而不是链表拉链
    - 内存泄漏：某个对象不再有用，但是占用的内存却不能被回收
      - key 的泄漏：ThreadLocalMap 中的 Entry 继承自 WeakReference，是弱引用
        - 弱引用的特点：如果这个对象只被弱引用关联（没有任何强引用关联），那么这个对象可以被回收
        - 所以弱引用不会阻止 GC
      - value 的泄漏
        - ThreadLocalMap 的每个 Entry 都是一个对 key 的弱引用，同时每个 Entry 都包含了一个对 value 的强引用
        - 正常情况下，当线程终止，保存在 ThreadLocal 里的 value 会被垃圾回收，因为没有任何强引用了
        - 但是，如果线程不终止（比如线程需要保持很久），那么 key对应的 value 就不能被回收，因为有以下的调用链：Thread->ThreadLocalMap->Entry(key 为 null)->Value
        - 因为 value 和 Thread 之间还存在这个强引用链路，所以导致 value 无法回收 就可能导致出现 OOM
        - JDK 已经考虑到这个问题，所以在 set，remove，rehash 方法中会扫描 key 为 null 的 Entry，并把对应的 value 设置为 null，这样 value 对象就可以被回收
        - 但是如果一个 ThreadLocal 不被使用，那么实际上 set，remove，rehash 方法就不会被调用，如果同时线程又不停止，那么调用链就一直存在，就导致了 value 的内存泄漏
      - 如何避免内存泄漏
        - 使用完 ThreadLocal 后应该调用 remove 方法
- 栈封闭 --- 把变量写在线程内部
  - 在方法里新建的局部变量，实际上是存储在每个线程私有的栈空间，而每个栈的栈空间是不能被其他线程所访问到的，所以不会有线程安全问题
### 线程管理

#### 线程池

- 线程池的好处
  - 加快响应速度
  - 合理利用 CPU 和内存
  - 统一管理
- 线程池适用的场合
  - 服务器接受大量请求时，使用线程池可以大大减少线程的创建和销毁次数，提高服务器的工作效率
  - 实际开发中，如果需要创建 5 个以上的线程，那么就可以使用线程池来管理
- 线程池构造函数的参数
  - corePoolSize
    - 核心线程数：线程池再完成初始化后，默认情况下，线程池中并没有任何线程，线程池会等待有任务到来时，再创建新线程去执行任务
  - maxPoolSize
    - 线程池有可能在核心线程数的基础上，额外增加一些线程，但是这些新增的线程数有一个上限，这就是最大量 maxPoolSize
  - keepAliveTime
    - 如果线程池当前的线程数多于 corePoolSize。那么如果多余的线程空闲时间超过 keepAliveTime，它们就会被终止
  - workQueue
    - 有 3 种最常见的队列类型
      - 直接交接：SynchronousQueue
      - 无界队列：LinkedBlockingQueue
      - 有界队列：ArrayBlockingQueue
  - threadFactory
    - 新的线程是由 ThreadFactory 创建的，默认使用 Executors.defaultThreadFactory()，创建出来的线程都在同一线程组，拥有同样的 NORM_PRIORITY 优先级并且斗不是守护线程。如果自己制定 ThreadFactory。那么就可以改变线程名、线程组、优先级、是否是守护线程等
    - 通常使用默认的 ThreadFactory
  - Handler
- 添加线程规则
  - 如果线程数小于 corePoolSize，即使其他工作线程处于空闲状态，也会创建一个新线程来运行新任务
  - 如果线程数等于（或大于）corePoolSize 但小于 maxPoolSize，则将任务放入队列
  - 如果队列已满，并且线程数小于 maxPoolSize，则创建一个新线程来运行任务
  - 如果队列已满，并且线程数大于或等于 maxPoolSize。则拒绝该任务
- 增减线程的特点
  - 通过设置 corePoolSize 和 maxPoolSize 相同，就可以创建固定大小的线程池
  - 线程池希望保持较少的线程数，并且只有负载变得很大时才增加它
  - 通过设置 maxPoolSize 为很高的值，例如 Integer.MAX_VALUE，可以允许线程容纳任意数量的并发任务
  - 是只有在队列填满时才创建多于 corePoolSize 的线程，所以如果使用的是无界队列（例如 LinkedBlockingQueue），那么线程数就不会超过 corePoolSize
- 线程池类型
  - newFixedTheadPool
    - 由于传进去的 LinkedBlockingQueue 是没有容量上限的，所以当请求数越来越多，并且无法及时处理完毕时，也就是请求堆积时，会容易造成占用大量的内存，可能会导致 OOM
  - newSingleThreadExecutor
    - 和 newFixedTheadPool 原理基本一样，只不过把线程数直接设置为 1，所以这也会导致同样的问题，当请求堆积时，可能会占用大量内存
  - newCachedThreadPool：可缓存线程池
    - 特点：无界线程池，具有自动回收多余线程的功能
    - 这里的弊端在于第二个参数 maximumPoolSize 被设置为 Integer.MAX_VALUE，这可能会导致创建数量非常多的线程，甚至导致 OOM
  - newScheduledThreadPool
    - 支持定时及周期性任务执行的线程池
- 正确创建线程池的方法
  - 根据不同的业务场景，自己设置线程池参数，比如我们的内存有多大，想给线程取什么名字等等
- 线程池数量设定为多少合适
  - CPU 密集型（加密、计算 hash 等）：最佳线程数为 CPU 核心数的 1-2 倍左右
  - 耗时 IO 型（读写数据库、文件、网络读写等）：最佳线程数一般会大于 CPU 核心数很多倍，以 JVM 线程监控显示繁忙情况为依据，保证线程空闲可以衔接上，参考 Brain Goetz 推荐的计算方法：
    - 线程数 = CPU 核心数 * (1 + 平均等待时间 / 平均工作时间)
- 线程池状态
  - RUNNING：接受新任务并处理排队任务
  - SHUTDOWN：不接受新任务，但处理排队任务
  - STOP：不接受新任务，也不处理排队任务，并中断正在进行的任务
  - TIDYING：所有任务都已终止，workerCount 为 0 时，线程会转换到 TIDYING 状态，并将运行 terminate() 钩子方法
  - TERMINATED：terminate() 运行完成
- 线程池注意点
  - 避免任务堆积
  - 避免线程数过度增加
  - 排查线程泄漏

#### 获取子线程的执行结果

- Runnable 的缺陷
  - 不能返回一个返回值
  - 也不能抛出 checked Exception
- Callable 接口
  - 类似于 Runnable，被其他线程执行的任务
  - 实现 call 方法
  - 有返回值
- Callable 和 Future 的关系
  - 可以用 Future.get来获取 Callable 接口返回的执行结果、，还可以通过 Future.isDone() 来判断任务是否已经执行完了，以及取消这个任务，限时获取任务的结果等
  - 在 call() 未执行完毕之前，调用get() 的线程（假定此时是主线程）会被阻塞，直到 call() 返回了结果后，此时 future,get() 才会得到该结果，然后主线程才会切换到 Runnable 状态
  - 所以 Future 是一个存储器，它存储了 call() 这个任务的结果，而这个任务的执行时间是无法提前确定的，因为者完全取决于 call() 执行的情况
- Future 的方法
  - get()：获取结果
    - get 方法的行为取决于 Callable 任务的状态，只有以下这 5 种情况：
      - 任务正常完成：get 方法会立刻返回结果
      - 任务尚未完成（任务还没开始或进行中）：get 将阻塞并直到任务完成
      - 任务执行过程中抛出 Exception：get 方法会抛出 ExecutionException：这里抛出的异常是 call() 执行时产生的那个异常，看到这个异常类型是 java.util.concurrent.ExecutionException。不论 call() 执行时抛出的异常类型是什么，最后 get 方法抛出的异常都是 ExecutionException
      - 任务被取消：get 方法会抛出 CancellationException
      - 任务超时：get 方法有一个重载方法，是传入一个延迟时间的，如果时间到了还没有获取结果，get 方法 就会抛出 TimeoutException
  - get(long timeout, TimeUnit unit)：有超时的获取
    - 超时的需求很常见
    - 用 get(long timeout, TimeUnit unit) 时，如果 call() 在规定时间内完成了任务，那么就会正常获取到返回值；而如果再指定时间内没有计算出结果，那么就抛出 TimeoutException
    - 超时不获取，任务需取消
  - cancel 方法：取消任务的执行
    - 如果这个任务还没有开始执行，任务会被正常取消，未来也不会被执行，方法返回 true
    - 如果任务已完成，或者已取消：那么 cancel() 会执行失败，方法返回 false
    - 如果这个任务已经开始执行了，那么这个取消方法将不会直接取消该任务，而是会根据我们填的参数 may InterruptIfRunning 做判断
    - Future.cancel(true) 适用于：
      - 任务能够处理 interrupt
    - Future.cancel(false) 仅用于避免启动尚未启动的任务，适用于：
      - 未能处理 interrupt 的任务
      - 不清楚任务是否支持取消
      - 需要等待已经开始的任务执行完成 
  - 
  - isDone()：判断线程是否执行完毕
  - isCancelled()：判断是否被取消
- 用法 1：用线程池的 submit 方法返回 Future 对象
  - 首先，我们要给线程池提交我们的任务，提交时线程池会立刻返回给我们一个空的 Future 容器。当线程的任务一旦执行完毕，也就是当我们可以获取结果时，线程池便会把该结果填入到之前给我们的那个 Future 中去（而不是创建一个新的 Future），我们此时便可以从该 Future 中获得任务执行的结果
- 用法 2：用 FutureTask 来创建 Future
  - 用 FutureTask 来获取 Future 和任务的结果
  - FutureTask 是一种包装器，可以把 Callable 转化为 Future 和 Runnable，它同时实现二者的接口
  - 它既可以作为 Runnable被线程执行，又可以作为 Future 得到 Callable 的返回值
  - 把 Callable 实例当作参数，生成 FutureTask 的对象，然后把这个对象当作一个 Runnable 对象，用线程池或者另起线程去执行这个 Runnable 对象，最后通过 FutureTask 获取刚才执行的结果
- Future 的注意点
  - 当 for 循环批量获取 future 的结果时，容易发生一部分线程很慢的情况，get 方法调用时应使用 timeout 限制
  - Future 的生命周期不能后退
    - 生命周期只能前进，不能后退。就和线程池的生命周期一样，一旦完全完成了任务，它就永久停在了 "已完成" 的状态，不能重头再来

### 线程间配合

- 控制并发流程
  - 控制并发流程的工具类，作用就是更容易地让线程之间合作
  - 让线程之间相互配合，来满足业务逻辑
  - 比如让线程 A 等待线程 B 执行完毕后再执行等合作策略

- Semaphore
  - 作用：信号量，可以通过控制 "许可证" 的数量。来保证线程之间的配合
  - 用来限制或管理数量有限的资源的使用情况
  - 信号量的作用就是维护一个 "许可证" 的计数，线程可以获取许可证，那信号量剩余的许可证就减一，线程也可以释放一个许可证，那信号量剩余的许可证就加一，当信号量所拥有的许可证为 0，那么下一个还想获取许可证的线程，就需要等待，直到有另外的线程释放了许可证
  - 说明：线程只有在拿到 "许可证" 后才能继续运行。相比于其他的同步器更灵活
  - 使用流程
    - 初始化 Semaphore 并指定许可证的数量
    - 在需要被执行的代码前加 acquire() 或者 acquireUninterruptibly()
    - 在任务执行结束后，调用 release() 来释放许可证
  - 重要方法
    - new Semaphore(int permits, boolean fair)：可以设置是否使用公平策略，如果传入 true，那么 Semaphore 会把之前等待的线程放到 FIFO 的队列里，以便于当有了新的许可证，可以分发给之前等了最长时间的线程
    - tryAcquire()：看看现在有没有空闲的许可证，如果有的话就获取，如果没有也没关系，我不必陷入阻塞，可以去做别的事，过一会儿再来查看许可证的空闲情况
    - tryAcquire(timeout)：和 tryAcquire() 一样，多了一个超时时间，比如 "在 3 秒内获取不到许可证，我就去做别的事"
  - 信号量特殊用法
    - 比如 TaskA 会调用很消耗资源的 method1()，而 TaskB 调用的是不太消耗资源的 method2()，假设我们一共有 5 个许可证。那么我们就可以要求 TaskA 获取 5 个许可证才能执行，而 TaskB 只需要获取到 1 个就能执行，这样就避免 A 和 B同时运行的情况，可以根据自己的需求合理分配资源
  - 注意点
    - 获取和释放的许可证数量必须一致，否则比如每次都获取 2 个但是只释放 1 个甚至不释放，随着时间的推移，到最后许可证数量不够用，会导致程序卡死
    - 在初始化 Semaphore 时设置公平性，一般设置为 true 会更合理
    - 并不是必须由获取许可证的线程释放了那个许可证，事实上获取和释放许可证对线程并无要求，也许是 A 获取了然后由 B 释放，只要逻辑合理即可
    - 信号量的作用，除了控制临界区最多有 N 个线程访问外，另一个作用是可以实现 "条件等待"，例如线程 1 需要在线程 2 完成准备工作后才能开始工作，那么线程 1 acquire()，而线程 2 完成任务后 release()，这样就相当于 轻量级的 CountDownLatch
- CyclicBarrier
  - 作用：线程会等待，直到足够多线程达到了事先规定的数量。一旦达到触发条件，就可以进行下一步的动作。
  - 说明：适用于线程之间相互等待处理结果就绪的场景
  - 当有大量线程相互配合，分别计算不同任务，并且需要最后统一汇总时，可以使用 CyclicBarrier。CyclicBarrier 可以构造一个集结点，当某一线程执行完毕，它就会到集结点等待，直到所有线程都到了集结点，那么该栅栏就被撤销，所有线程再统一出发，继续执行剩下的任务
  - 生活中的例子：咱们 3 个人明天中午再学校碰面，都到齐后，一起讨论下学期的计划
- CylicBarrier 和 CountDownLatch 的区别
  - 作用不同
    - CylicBarrier 要等固定数量的线程都到达了栅栏位置才能继续执行，而 CountDownLatch 只需要等待数字到 0，也就是说，CountDownLatch 用于事件，但是 CylicBarrier 是用于线程的
  - 可重用不同
    - CountDownLatch 在倒数到 0 并触发门闩打开后，就不能再次使用了，除非创建新的实例；而 CylicBarrier 可以重复使用
- Phaser
  - 说明：和 CyclicBarrier 类似，但是计数可变
  - 作用：Java 7 加入的
- CountDownLatch 
  - 作用：和 CyclicBarrier 类似，数量递减到 0 时，触发动作
  - 说明：不可重复使用（如果需要重新计数，可以考虑使用 CyclicBarrier 或者创建新的 CountDownLatch 实例）
  - CountDownLatch(int count)：仅有一个构造函数，参数 count 为需要倒数的数值
  - await()：调用 await() 的线程会被挂起，它会等待直到 count 值为 0 才继续执行
  - countDown()：将 count 值减 1，直到为 0 时，等待的线程会被唤醒
- Exchanger
  - 作用：让两个线程在合适时交换对象
  - 说明：适用场景：当两个线程工作在同一个类的不同实例上时，用于交换数据
- Condition
  - 作用：可以控制线程的 "等待" 和 "唤醒"
  - 说明：是 Object.wait() 的升级版
  - 当线程 1 需要等待某个条件时，它会去执行 condition.await()，一旦执行了 await()，线程会进入阻塞状态
  - 然后通常会有另外一个线程，假设是线程 2 去执行对应的条件，直到之歌条件达成的时候，线程 2 就会去执行 condition.signal()，这时 JVM 就会从阻塞的线程里找到那些等待该 condition 的线程，当线程 1 收到可执行信号时，它的线程状态就会变成 Runnable 可执行状态
  - signalAll() 会唤起所有的正在等待的线程
  - signal() 是公平的，只会唤起那个等待时间最长的线程
  - 注意点
    - 用来代替相应的 Object.wait()/notify()
    - await() 会自动释放持有的 Lock 锁，和 Object.wait() 一样，不需要手动先释放锁
    - 调用 await() 时，必须持有锁，否则会抛出异常，和 Object.wait() 一样

### AQS

- 为什么需要 AQS
  - 锁和协作类有共同点：闸门
  - ReentrantLock 和 Semaphore、CountDownLatch、ReentrantWriteLock 都有类似的 "协作"（或者叫 "同步"）功能，其实它们底层用了一个共同的基类：AQS
- Semaphore 内部有一个 Sync 类，Sync 类继承了 AQS
- CountDownLatch 也一样
- AQS 的比喻
  - Semaphore：一个人面试完了以后，后一个人才能进来继续面试
  - CountDownLatch：群面，等待 10 人到齐
  - Semaphore、CountDownLatch这些同步工具类要做的就只是写下自己的 "要人" 规则。比如 "出一个，进一个"，或者说 "凑齐 10 人，一起面试"
  - 剩下的招呼面试者的脏活累活交给 AQS 来做
- 如果没有 AQS
  - 就需要每个协作工具自己实现：同步状态的原子性管理、线程的阻塞与解除阻塞、队列的管理
  - 在并发场景下，自己正确且高效实现这些，是相当有难度的
- AQS 的作用
  - 用于构建锁、同步器、协作工具类的工具类（框架）
  - 有了 AQS，构建线程协作类就容易多了
- AQS 内部原理
  - state
    - 这里 state 具体含义，会根据具体实现类的不同而不同，比如在 Semaphore 里，它表示 "剩余的许可证的数量"，而在 CountDownLatch 里，它表示 "还需要倒数的数量"
    - state 是 volatile 修饰的，会被并发修改，所以所有修改 state 的方法都需要保证线程安全，比如 getState、setState 以及 compareAndSetState 操作来读取和更新这个状态。这些方法都依赖于 j.u.c.atomic 包的支持
    - 在 ReentrantLock 中，state 表示锁的占有情况，包括可重入计数，当 state 的值为 0 的时候，标识该 Lock 不被任何线程所占有
  - 控制线程抢锁和配合的 FIFO 队列
    - 这个队列用来存放 "等待的线程"，AQS 就是 "排队管理器"，当多个线程争用同一把锁时，必须有排队机制将那些没能拿到锁的线程串在一起。当锁释放时，锁管理器就会挑选一个合适的线程来占有这个刚刚释放的锁
    - AQS 会维护一个等待的线程队列，把线程都放在这个队列里
    - 这是一个双向形式的队列
  - 期望协作工具类去实现的获取/释放等重要方法
    - 获取方法：获取操作会依赖 state 变量，经常会阻塞（比如获取不到锁的时候）
      - 在 Semaphore 中，获取就是 acquire 方法，作用是获取一个许可证
      - 在 CountDownLatch 里，获取就是 await 方法，作用就是 "等待直到倒数结束"
    - 释放方法：释放操作不会阻塞
      - 在 Semaphore 中，释放就是 release 方法有，作用就是释放一个许可证
      - 在 CountDownLatch 里，获取就是 countDown 方法，作用是 "倒数 1 个数"
    - 需要重写 tryAcquire 和 tryRelease 等方法
- AQS 用法
  - 第一步：写一个类，想好协作的逻辑，实现获取/释放方法
  - 第二步：内部写一个 Sync 类继承AbstractQueueSynchronizer
  - 第三步：根据是否独占来重写 tryAcquire/tryRelease 或 tryAcquireShared(int acquires) 和 tryReleaseShared(int releases) 等方法，在之前的获取/释放方法中调用 AQS 的acquire/release 或者 Shared 方法
- CountDownLatch 源码分析
  - 内部类 Sync 继承 AQS
  - AQS 在 CountDownLatch 的应用
    - 构造函数
    - getCount
    - countDown
    - await
  - AQS 在 CountDownLatch 的总结
    - 调用 CountDownLatch 的 await 方法时，便会尝试获取 "共享锁"，不过一开始是获取不到该锁的，于是线程被阻塞
    - 而 "共享锁" 可获取的条件就是 "锁计数器" 的值为 0
    - 而 "锁计数器" 的初始值为 count，每当一个线程调用该 CountDownLatch 对象的 countDown 方法时，才将 "锁计数器" -1
    - count 个线程调用 countDown() 之后， "锁计数器" 才为 0，而前面提及的等待获取共享锁的线程才能继续运行
  - AQS 在 Semaphore 的应用
    - 在 Semaphore 中， state 表示许可证的剩余数量
    - 看 tryAcquire 方法，判断 nonfairTryAcquireShared 大于等于 0 的话，代表成功
    - 这里会检查剩余许可证数量够不够这次需要的，用减法来计算，如果直接不够，那就返回负数，表示失败，如果够了，就用自旋加 compareAndSetState 来改变 state 状态，直到改变成功返回正数；或者是期间如果被其他人修改了导致剩余数量不够了，那也返回负数代表获取失败
  - AQS 在 ReentrantLock 的应用
    - 分析释放锁的方法 tryRelease
      - 由于是可重入的，所以 state 代表重入的次数，每次释放锁，先判断是不是当前持有锁的线程释放的，如果不是就抛出异常，如果是，重入次数就减一，如果减到了 0，就说明完全释放了，于是 free 就是 true，并且把 state 设置为 0
    - 加锁的方法



