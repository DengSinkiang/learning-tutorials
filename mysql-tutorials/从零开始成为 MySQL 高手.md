#### 天天写 CRUD，你知道你的系统是如何跟 MySQL 打交道的吗

- MySQL 驱动到底是什么东西
  - 跟数据库建立网络连接，有网络连接，接着才能去发送请求给数据库服务器
- 数据库连接池到底是用来干什么的
  - 在一个池子里维持多个数据库连接，让多个线程使用里面的不同的数据库连接去执行 SQL 语句，然后执行完 SQL 语句之后，不要销毁这个数据库连接，而是把连接放回池子里，后续还可以继续使用
- MySQL 数据库的连接池是用来干什么的
  - 实际上 MySQL 中的连接池就是维护了与系统之间的多个数据库连接。除此之外，你的系统每次跟 MySQL 建立连接的时候，还会根据你传递过来的账号和密码，进行账号密码的验证，库表权限的验证

#### 为了执行SQL语句，你知道MySQL用了什么样的架构设计吗

- 一个不变的原则：网络连接必须让线程来处理
  - 网络连接必须得分配给一个线程去进行处理，由一个线程来监听请求以及读取请求数据，比如从网络连接中读取和解析出来一条我们的系统发送过去的 SQL 语句
- SQL 接口：负责处理接收到的 SQL 语句
- 查询解析器：让 MySQL 能看懂 SQL 语句
- 查询优化器：选择最优的查询路径
- 调用存储引擎接口，真正执行 SQL 语句
- 执行器：根据执行计划调用存储引擎的接口
  - 执行器就会去根据我们的优化器生成的一套执行计划，然后不停的调用存储引擎的各种接口去完成 SQL 语句的执行计划

#### 用一次数据更新流程，初步了解 InnoDB 存储引擎的架构设计

- InnoDB 的重要内存结构：缓冲池（Buffer Pool）
  - 会缓存很多的数据，以便于以后在查询的时候，万一你要是内存缓冲池里有数据，就可以不用去查磁盘
- undo 日志文件：如何让你更新的数据可以回滚
  - 写入数据的旧值便于回滚
- 更新 buffer pool 中的缓存数据
  - 当我们把要更新的那行记录从磁盘文件加载到缓冲池，同时对他加锁之后，而且还把更新前的旧值写入 undo 日志文件之后，我们就可以正式开始更新这行记录了，更新的时候，先是会更新缓冲池中的记录，此时这个数据就是脏数据了
- Redo Log Buffer：万一系统宕机，如何避免数据丢失
  - 必须要把对内存所做的修改写入到一个 Redo Log Buffer 里去，这也是内存里的一个缓冲区，是用来存
    放 redo 日志的
  - 所谓的 redo 日志，就是记录下来你对数据做了什么修改，比如对 "id=10这行记录修改了name字段的值为xxx"
- 如果还没提交事务，MySQL 宕机了怎么办
  - 其实在数据库中，哪怕执行一条 SQL 语句，其实也可以是一个独立的事务，只有当你提交事务之后，SQL 语句才算执行结束
  - 没有提交事务，那么此时如果 MySQL 崩溃，必然导致内存里 Buffer Pool 中的修改过的数据都丢失，同时你写入 Redo Log Buffer 中的 redo 日志也会丢失
  - 没提交事务，就代表他没执行成功，此时MySQL宕机虽然导致内存里的数据都丢失了，但是你会发现，磁盘上的数据依然还停留在原样子
- 提交事务的时候将 redo 日志写入磁盘中
  - 接着我们想要提交一个事务了，此时就会根据一定的策略把 redo 日志从 redo log buffer 里刷入到磁盘文件里去
  - 此时这个策略是通过 innodb_flush_log_at_trx_commit 来配置的，他有几个选项
    - 当这个参数的值为 0 的时候，那么你提交事务的时候，不会把 redo log buffer 里的数据刷入磁盘文件的，此时可能你都提交事务了，结果 mysql 宕机了，然后此时内存里的数据全部丢失。相当于你提交事务成功了，但是由于 MySQL 突然宕机，导致内存中的数据和 redo 日志都丢失了
    - 当这个参数的值为 1 的时候，你提交事务的时候，就必须把 redo log 从内存刷入到磁盘文件里去，只要事务提交成功，那么 redo log 就必然在磁盘里了
    - 当这个参数的值为 2 的时候，提交事务的时候，把 redo 日志写入磁盘文件对应的 os cache 缓存里去，而不是直接进入磁盘文件，可能 1 秒后才会把 os cache 里的数据写入到磁盘文件里去

#### 借着更新语句在 InnoDB 存储引擎中的执行流程，聊聊 binlog 是什么

- redo日志刷盘策略的选择建议
  - 通常建议是设置为1。提交事务的时候，redo日志必须是刷入磁盘文件里的。这样可以严格的保证提交事务之后，数据是绝对不会丢失的，因为有redo日志在磁盘文件里可以恢复你做的所有修改
  - 如果要是选择0的话，可能你提交事务之后，mysql宕机，那么此时redo日志没有刷盘，导致内存里的redo日志丢失，你提交的事务更新的数据就丢失了
  - 如果要是选择2的话，如果机器宕机，虽然之前提交事务的时候，redo日志进入os cache了，但是还没进入磁盘文件，此时机器宕机还是会导致os cache里的redo日志丢失
- MySQL binlog到底是什么东西
  - redo log，他是一种偏向物理性质的重做日志，因为他里面记录的是类似这样的东西，"对哪个
    数据页中的什么记录，做了个什么修改"。redo log本身是属于InnoDB存储引擎特有的
  - binlog叫做归档日志，他里面记录的是偏向于逻辑性的日志，类似于 "对users表中的id=10的一行数据做了更新操作，更新以后的值是什么"
- 提交事务的时候，同时会写入binlog
  - 在我们提交事务的时候，会把redo log日志写入磁盘文件中去。然后其实在提交事务的时候，我们同时还会把这次更新对应的binlog日志写入到磁盘文件中去
  - 跟InnoDB存储引擎进行交互的组件加入了之前提过的执行器这个组件，他会负责跟InnoDB进行交互，包括从磁盘里加载数据到Buffer Pool中进行缓存，包括写入undo日志，包括更新Buffer Pool里的数据，以及写入redo log buffer，redo log刷入磁盘，写binlog，等等。执行器是非常核心的一个组件，负责跟存储引擎配合完成一个SQL语句在磁盘与内存层面的全部数据更新操作
- binlog日志的刷盘策略分析
  - 有一个sync_binlog参数可以控制binlog的刷盘策略，他的默认值是0，此时你把binlog写入磁盘的时候，其实不是直接进入磁盘文件，而是进入os cache内存缓存
  - 如果要是把sync_binlog参数设置为1的话，那么此时会强制在提交事务的时候，把binlog直接写入到磁盘文件里去，那么这样提交事务之后，哪怕机器宕机，磁盘上的binlog是不会丢失的
- 基于binlog和redo log完成事务的提交
  - 当我们把binlog写入磁盘文件之后，接着就会完成最终的事务提交，此时会把本次更新对应的binlog文件名称和这次更新的binlog日志在文件里的位置，都写入到redo log日志文件里去，同时在redo log日志文件里写入一个commit标记
- 最后一步在redo日志中写入commit标记的意义是什么
  - 必须是在 redo log 中写入最终的事务 commit 标记了，然后此时事务提交成功，而且 redo log 里有本次更新对应的日志，binlog 里也有本次更新对应的日志 ，redo log 和 binlog 完全是一致的
- 后台IO线程随机将内存更新后的脏数据刷回磁盘
  - MySQL 有一个后台的 IO 线程，会在之后某个时间里，随机的把内存buffer pool中的修改后的脏数据给刷回到磁盘上的数据文件里去
- 基于更新数据的流程，总结一下InnoDB存储引擎的架构原理
  - InnoDB存储引擎主要就是包含了一些buffer pool、redo log buffer等内存里的缓存数据，同时还包含了一些undo日志文件，redo日志文件等东西，同时mysql server自己还有 binlog日志文件
  - 在你执行更新的时候，每条SQL语句，都会对应修改buffer pool里的缓存数据、写undo日志、写redo log buffer几个步骤
  - 但是当你提交事务的时候，一定会把redo log刷入磁盘，binlog刷入磁盘，完成redo log中的事务commit标记；最后后台的IO线程会随机的把buffer pool里的脏数据刷入磁盘里去

#### 生产经验：互联网公司的生产环境数据库是如何进行性能测试的

- QPS 和 TPS
  - QPS：Query Per Second
  - TPS：Transaction Per Second
- IO相关的压测性能指标
  - （1）IOPS：这个指的是机器的随机IO并发处理的能力，比如机器可以达到200 IOPS，意思就是说每秒可以执行200个随机IO读写请求
  - （2）吞吐量：这个指的是机器的磁盘存储每秒可以读写多少字节的数据量
  - （3）latency：这个指标说的是往磁盘里写入一条数据的延迟
- 压测的时候要关注的其他性能指标
  - （1）CPU负载：CPU负载是一个很重要的性能指标，因为假设你数据库压测到了每秒处理3000请求了，可能其他的性能指标都还正常，但是此时CPU负载特别高，那么也说明你的数据库不能继续往下压测更高的QPS了，否则CPU是吃不消的
  - （2）网络负载：这个主要是要看看你的机器带宽情况下，在压测到一定的QPS和TPS的时候，每秒钟机器的网卡会输入多少MB数据，会输出多少MB数据，因为有可能你的网络带宽最多每秒传输100MB的数据，那么可能你的QPS到1000的时候，网卡就打满了，已经每秒传输100MB的数据了，此时即使其他指标都还算正常，但是你也不能继续压测下去了
  - （3）内存负载：这个就是看看在压测到一定情况下的时候，你的机器内存耗费了多少，如果说机器内存耗费过高了，说明也不能继续压测下去了

#### 从数据的增删改开始讲起，回顾一下Buffer Pool在数据库里的地位

- Buffer Pool的一句话总结
  - 数据库中我们第一个必须要搞清楚的核心组件，因为增删改操作首先就是针对这个内存中的 Buffer Pool 里的数据执行的，同时配合了后续的 redo log、刷磁盘等机制和操作
  - 数据库的一个内存组件，里面缓存了磁盘上的真实数据，然后我们的 Java 系统对数据库执行的增删改操作，其实主要就是对这个内存数据结构中的缓存数据执行的

#### Buffer Pool 这个内存数据结构到底长个什么样子

- 如何配置你的 Buffer Pool 的大小

  - Buffer Pool 默认情况下是 128MB

  - 比如我们的数据库如果是 16 核 32G 的机器，那么你就可以给 Buffer Pool 分配个 2GB 的内存

    ```
    [server]
    innodb_buffer_pool_size = 2147483648
    ```

- 数据页：MySQL 中抽象出来的数据单位

  - Buffer Pool 中存放的是一个一个的数据页，每个数据页里放了很多行数据

- 磁盘上的数据页和 Buffer Poo l中的缓存页是如何对应起来的

  - 实际上默认情况下，磁盘中存放的数据页的大小是 16KB，也就是说，一页数据包含了 16KB 的内容
  - 而 Buffer Pool 中存放的一个一个的数据页，我们通常叫做缓存页，因为毕竟 Buffer Pool 是一个缓冲池，里面的数据都是从磁盘缓存到内存去的
  - 而 Buffer Pool 中默认情况下，一个缓存页的大小和磁盘上的一个数据页的大小是一一对应起来的，都是 16KB

- 缓存页对应的描述信息是什么

  - 对于每个缓存页，他实际上都会有一个描述信息，这个描述信息大体可以认为是用来描述这个缓存页的
  - 比如包含如下的一些东西：这个数据页所属的表空间、数据页的编号、这个缓存页在Buffer Pool中的地址以及别的一些杂七杂八的东西
  - 每个缓存页都会对应一个描述信息，这个描述信息本身也是一块数据，在Buffer Pool中，每个缓存页的描述数据放在最前面，然后各个缓存页放在后面
  - 注意
    - Buffer Pool 中的描述数据大概相当于缓存页大小的 5% 左右，也就是每个描述数据大概是 800 个字
      节左右的大小，然后假设你设置的 Buffer Pool大小是 128MB，实际上 Buffer Pool 真正的最终大小会超出一些，可能有个 130 多 MB 的样子，因为他里面还要存放每个缓存页的描述数据

#### 从磁盘读取数据页到 Buffer Pool 的时候，free 链表有什么用

- 数据库启动的时候，是如何初始化 Buffer Pool 的
  - 数据库只要一启动，就会按照你设置的 Buffer Pool 大小，稍微再加大一点，去找操作系统申请一块内存区域，作为 Buffer Pool 的内存区域
  - 然后当内存区域申请完毕之后，数据库就会按照默认的缓存页的 16KB 的大小以及对应的 800 个字节左右的描述数据的大小，在 Buffer Pool 中划分出来一个一个的缓存页和一个一个的他们对应的描述数据
  - 然后当数据库把 Buffer Pool 划分完毕之后，只不过这个时候，Buffer Pool 中的一个一个的缓存页都是空的，里面什么都没有，要等数据库运行起来之后，当我们要对数据执行增删改查的操作的时候，才会把数据对应的页从磁盘文件里读取出来，放入 Buffer Pool 中的缓存页中
- 怎么知道哪些缓存页是空闲的
  - 默认情况下磁盘上的数据页和缓存页是一 一对应起来的，都是 16KB，一个数据页对应一个缓存页
  - 数据库会为 Buffer Pool 设计一个 free 链表，他是一个双向链表数据结构，这个 free 链表里，每个节点就是一个空闲的缓存页的描述数据块的地址，也就是说，只要你一个缓存页是空闲的，那么他的描述数据块就会被放入这个 free 链表中
  - free 链表有一个基础节点，他会引用链表的头节点和尾节点，里面还存储了链表中有多少个描述数据块的节点，也就是有多少个空闲的缓存页
- free 链表占用多少内存空间
  - 这个 free 链表，他本身其实就是由 Buffer Pool 里的描述数据块组成的，你可以认为是每个描述数据块里都有两个指针，一个是 free_pre，一个是 free_next，分别指向自己的上一个 free 链表的节点，以及下一个 free 链表的节点
  - 对于 free 链表而言，只有一个基础节点是不属于 Buffer Pool 的，他是 40 字节大小的一个节点，里面就存放了 free 链表的头节点的地址，尾节点的地址，还有 free 链表里当前有多少个节点
- 如何将磁盘上的页读取到 Buffer Pool 的缓存页中
  - 首先，我们需要从free链表里获取一个描述数据块，然后就可以对应的获取到这个描述数据块对应的空闲缓存页
  - 接着我们就可以把磁盘上的数据页读取到对应的缓存页里去，同时把相关的一些描述数据写入缓存页的描述数据块里去，比如这个数据页所属的表空间之类的信息，最后把那个描述数据块从 free 链表里去除就可以了
- 怎么知道数据页有没有被缓存
  - 我们在执行增删改查的时候，肯定是先看看这个数据页有没有被缓存，如果没被缓存就走上面的逻辑，从 free 链表中找到一个空闲的缓存页，从磁盘上读取数据页写入缓存页，写入描述数据，从 free 链表中移除这个描述数据块
  - 但是如果数据页已经被缓存了，那么就会直接使用了
  - 所以其实数据库还会有一个哈希表数据结构，他会用表空间号+数据页号，作为一个 key，然后缓存页的地址作为 value
  - 当你要使用一个数据页的时候，通过 "表空间号+数据页号" 作为 key 去这个哈希表里查一下，如果没有就读取数据页，如果已经有了，就说明数据页已经被缓存了
  - 引入数据页缓存哈希表的结构，每次你读取一个数据页到缓存之后，都会在这个哈希表中写入一个 key-value 对，key 就是表空间号+数据页号，value 就是缓存页的地址，那么下次如果你再使用这个数据页，就可以从哈希表里直接读取出来他已经被放入一个缓存页了

#### 当我们更新Buffer Pool中的数据时，flush链表有什么用

- 脏数据页到底为什么会脏
  - 在执行增删改的时候，如果发现数据页没缓存，那么必然会基于 free 链表找到一个空闲的缓存页，然后读取到缓存页里去，但是如果已经缓存了，那么下一次就必然会直接使用缓存页
  - 反正不管怎么样，你要更新的数据页都会在 Buffer Pool 的缓存页里，供你在内存中直接执行增删改的操作
  - 接着你肯定会去更新 Buffer Pool 的缓存页中的数据，此时一旦你更新了缓存页中的数据，那么缓存页里的数据和磁盘上的数据页里的数据，缓存页是脏数据，脏页
- 哪些缓存页是脏页
  - 最终这些在内存里更新的脏页的数据，都是要被刷新回磁盘文件的。不可能所有的缓存页都刷回磁盘的，因为有的缓存页可能是因为查询的时候被读取到 Buffer Pool 里去的，可能根本没修改过
  - 所以数据库在这里引入了另外一个跟 free 链表类似的 flush 链表，这个 flush 链表本质也是通过缓存页的描述数据块中的两个指针，让被修改过的缓存页的描述数据块，组成一个双向链表
  - 凡是被修改过的缓存页，都会把他的描述数据块加入到 flush 链表中去，flush 的意思就是这些都是脏页，后续都是要 flush 刷新到磁盘上去的

#### 当 Buffer Pool 中的缓存页不够的时候，如何基于 LRU 算法淘汰部分缓存

- 如果 Buffer Pool 中的缓存页不够了怎么办
  - 在加载数据到缓存页的时候，必然是要加载到空闲的缓存页里去的，所以必须要从 free 链表中找一个空闲的缓存页，然后把磁盘上的数据页加载到那个空闲的缓存页里去
  - 不停的把磁盘上的数据页加载到空闲缓存页里去，free 链表中不停的移除空闲缓存页，迟早有那么一瞬间，你会发现 free 链表中已经没有空闲缓存页
- 如果要淘汰掉一些缓存数据，淘汰谁
  - 淘汰缓存页：把一个缓存页里被修改过的数据，给他刷到磁盘上的数据页里去，然后这个缓存页就可以清空了，让他重新变成一个空闲的缓存页
  - 接着你再把磁盘上你需要的新的数据页加载到这个腾出来的空闲缓存页
- 缓存命中率概念的引入
  - 一个缓存页的数据，经常会被修改和查询，比如在 100 次请求中，有 30 次都是在查询和修改这个缓存页里的数据。 那么此时我们可以说这种情况下，缓存命中率很高
  - 另外一个缓存页里的数据，就是刚从磁盘加载到缓存页之后，被修改和查询过1次，之后100次请求中没有一次是修改和查询这个缓存页的数据的，那么此时我们就说缓存命中率有点低，因为大部分请求可能还需要走磁盘查询数据，他们要操作的数据不在缓存中
  - 将缓存命中率低的缓存页的数据刷入到磁盘去，腾出来一个空闲的缓存页
- 引入 LRU 链表来判断哪些缓存页是不常用的
  - Least Recently Used，最近最少使用
  - LRU 链表的工作原理
    - 假设我们从磁盘加载一个数据页到缓存页的时候，就把这个缓存页的描述数据块放到 LRU 链表头部去，那么只要有数据的缓存页，他都会在 LRU 里了，而且最近被加载数据的缓存页，都会放到 LRU 链表的头部去
    - 然后假设某个缓存页的描述数据块本来在 LRU 链表的尾部，后续你只要查询或者修改了这个缓存页的数据，也要把这个缓存页挪动到 LRU 链表的头部去，也就是说最近被访问过的缓存页，一定在 LRU 链表的头部
    - 当你的缓存页没有一个空闲的时候，你是不是要找出来那个最近最少被访问的缓存页去刷入磁盘？此
      时你就直接在 LRU 链表的尾部找到一个缓存页，他一定是最近最少被访问的那个缓存页
    - 然后你就把 LRU 链表尾部的那个缓存页刷入磁盘中，然后把你需要的磁盘数据页加载到腾出来的空闲缓存页中即可

#### 简单的 LRU 链表在 Buffer Pool 实际运行中，可能导致哪些问题

- 预读带来的一个巨大问题
  - MySQL 的预读机制，这个所谓预读机制，说的就是当你从磁盘上加载一个数据页的时候，他可能会连带着把这个数据页相邻的其他数据页，也加载到缓存里去
- 哪些情况下会触发 MySQL 的预读机制
  - 预读机制一下子把相邻的数据页加载进缓存，放入 LRU 链表前面的隐患了，预读机制加载进来的缓存页可能根本不会有人访问，结果他却放在了 LRU 链表的前面，此时可能会把 LRU 尾部的那些被频繁访问的缓存页刷入磁盘中
  - （1）有一个参数是 innodb_read_ahead_threshold，他的默认值是 56，意思就是如果顺序的访问了一个区里的多个数据页，访问的数据页的数量超过了这个阈值，此时就会触发预读机制，把下一个相邻区中的所有数据页都加载到缓存里去
  - （2）如果 Buffer Pool 里缓存了一个区里的 13 个连续的数据页，而且这些数据页都是比较频繁会被访问的，此时就会直接触发预读机制，把这个区里的其他的数据页都加载到缓存里去。这个机制是通过参数innodb_random_read_ahead 来控制的，他默认是 OFF，也就是这个规则是关闭的
- 另外一种可能导致频繁被访问的缓存页被淘汰的场景
  - 全表扫描
    - 这个所谓的全表扫描，意思就是类似如下的 SQL 语句：SELECT * FROM USERS 此时他没加任何一个where 条件，会导致他直接一下子把这个表里所有的数据页，都从磁盘加载到 Buffer Pool 里去。这个时候他可能会一下子就把这个表的所有数据页都一一装入各个缓存页里去！此时可能 LRU 链表中排在前面的一大串缓存页，都是全表扫描加载进来的缓存页！那么如果这次全表扫描过后，后续几乎没用到这个表里的数据呢？
    - 此时 LRU 链表的尾部，可能全部都是之前一直被频繁访问的那些缓存页
    - 然后当你要淘汰掉一些缓存页腾出空间的时候，就会把 LRU 链表尾部一直被频繁访问的缓存页给淘汰掉了，而留下了之前全表扫描加载进来的大量的不经常访问的缓存页

#### MySQL 是如何基于冷热数据分离的方案，来优化 LRU 算法的

- 基于冷热数据分离的思想设计 LRU 链表
  - 真正的 LRU 链表，会被拆分为两个部分，一部分是热数据，一部分是冷数据，这个冷热数据的比例是由innodb_old_blocks_pct 参数控制的，他默认是 37，也就是说冷数据占比 37%
- 数据页第一次被加载到缓存的时候
  - 缓存页会被放在冷数据区域的链表头部
- 冷数据区域的缓存页什么时候会被放入到热数据区域
  - MySQL 设定了一个规则，他设计了一个 innodb_old_blocks_time 参数，默认值 1000，也就是 1000 毫秒
  - 也就是说，必须是一个数据页被加载到缓存页之后，在 1s 之后，你访问这个缓存页，他才会被挪动到热数据区域的链表头部去
  - 是数据加载到缓存页之后过了 1s，你再访问这个缓存页，他就会被放入热数据区域的链表头部，如果是你数据刚加载到缓存页，在 1s 内你就访问缓存页，此时他是不会把这个缓存页放入热数据区域的头部的

#### 基于冷热数据分离方案优化后的 LRU 链表，是如何解决之前的问题的

- 对于预读以及全表扫描加载进来的一大堆缓存页
  - 放在LRU链表的冷数据区域的前面
  - 假设这个时候热数据区域已经有很多被频繁访问的缓存页了，你会发现热数据区域还是存放被频繁访问的缓存页的，只要热数据区域有缓存页被访问，他还是会被移动到热数据区域的链表头部去
- 预读机制和全表扫描加载进来的缓存页，能进热数据区域吗
  - 如果你仅仅是一个全表扫描的查询，此时你肯定是在 1s 内就把一大堆缓存页加载进来，然后就访问了这些缓存页一下，通常这些操作 1s 内就结束了。所以基于目前的一个机制，可以确定的是，这种情况下，那些缓存页是不会从冷数据区域转移到热数据区域的
  - 除非你在冷数据区域里的缓存页，在 1s 之后还被人访问了，那么此时他们就会判定为未来可能会被频繁访问的缓存页，然后移动到热数据区域的链表头部去
- 如果此时缓存页不够了，需要淘汰一些缓存，会怎么样
  - 直接就是可以找到 LRU 链表中的冷数据区域的尾部的缓存页，他们肯定是之前被加载进来的，而且加载进来 1s 过后都没人访问过，说明这个缓存页压根儿就没人愿意去访问他！他就是冷数据。所以此时就直接淘汰冷数据区域的尾部的缓存页，刷入磁盘
- 之前的一大堆问题解决了吗
  - 在这样的一套缓存页分冷热数据的加载方案，以及冷数据转化为热数据的时间限制方案，还有就是淘汰缓存页的时候优先淘汰冷数据区域的方案，基于这套方案，大家会发现，之前发现的问题，完美的被解决了
  - 因为那种预读机制以及全表扫描机制加载进来的数据页，大部分都会在 1s 之内访问一下，之后可能就再也不访问了，所以这种缓存页基本上都会留在冷数据区域里。然后频繁访问的缓存页还是会留在热数据区域里
  - 当你要淘汰缓存的时候，优先就是会选择冷数据区域的尾部的缓存页
- 总结
  - 刚加载数据的缓存页都是放冷数据区域的头部的，1s 过后被访问了才会放热数据区域的头部，热数据区域的缓存页被访问了，就会自动放到头部去

#### MySQL 是如何将LRU链表的使用性能优化到极致的

- LRU 链表的热数据区域是如何进行优化的
  - LRU 链表的热数据区域的访问规则被优化了一下，即你只有在热数据区域的后 3/4 部分的缓存页被访问了，才会给你移动到链表头部去。如果你是热数据区域的前面 1/4 的缓存页被访问，他是不会移动到链表头部去的

#### 对于LRU链表中尾部的缓存页，是如何淘汰他们刷入磁盘的

- Buffer Pool的缓存页以及几个链表的使用回顾
  - 比如数据加载到一个缓存页，free链表里会移除这个缓存页，然后lru链表的冷数据区域的头部会放入这个缓存页
  - 然后如果你要是修改了一个缓存页，那么flush链表中会记录这个脏页，lru链表中还可能会把你从冷数据区域移动到热数据区域的头部去
  - 如果你是查询了一个缓存页，那么此时就会把这个缓存页在lru链表中移动到热数据区域去，或者在热数据区域中也有可能会移动到头部去
  - 总之，MySQL在执行CRUD的时候，首先就是大量的操作缓存页以及对应的几个链表。然后在缓存页都满的时候，必然要想办法把一些缓存页给刷入磁盘，然后清空这几个缓存页，接着把需要的数据页加载到缓存页里去
- 定时把LRU尾部的部分缓存页刷入磁盘
  - 首先第一个时机，并不是在缓存页满的时候，才会挑选LRU冷数据区域尾部的几个缓存页刷入磁盘，而是有一个后台线程，他会运行一个定时任务，这个定时任务每隔一段时间就会把LRU链表的冷数据区域的尾部的一些缓存页，刷入磁盘里去，清空这几个缓存页，把他们加入回free链表去。所以实际上在缓存页没用完的时候，可能就会清空一些缓存页
  - 只要有这个后台线程定时运行，可能你的缓存页都没用完呢，人家就给你把一批冷数据的缓存页刷入磁盘，清空出来一批缓存页，那么你就多了一批可以使用的空闲缓存页
  - 所以如果在一个动态的运行效果中思考，大概就是你不停的加载数据到一些空闲的缓存页里去，然后这些缓存页可能被使用，会在lru链表中各种移动。然后同时有一个后台线程还不停的把冷数据区域的一些不用的缓存页刷入磁盘中，清空一些缓存页出来
  - 只要有缓存页被刷人磁盘，大家可以想象一下，那么这个缓存页必然会加入到free链表中，从flush链表中移除，从lru链表中移除
- 把flush链表中的一些缓存页定时刷入磁盘
  - 你一边不停的加载数据到缓存页里去，不停的查询和修改缓存数据，然后free链表中的缓存页不停的在减少，flush链表中的缓存页不停的在增加，Lyra链表中的缓存页不停的在增加和移动
  - 另外一边，你的后台线程不停的在把lru链表的冷数据区域的缓存页以及flush链表的缓存页，刷入磁盘中来清空缓存页，然后flush链表和lru链表中的缓存页在减少，free链表中的缓存页在增加
- 实在没有空闲缓存页了怎么办
  - 如果要从磁盘加载数据页到一个空闲缓存页中，此时就会从LRU链表的冷数据区域的尾部找到一个缓存页，他一定是最不经常使用的缓存页！然后把他刷入磁盘和清空，然后把数据页加载到这个腾出来的空闲缓存页里去

#### 生产经验：如何通过多个Buffer Pool来优化数据库的并发性能

- Buffer Pool在访问的时候需要加锁吗

  - 多线程并发访问一个Buffer Pool，必然是要加锁的，然后让一个线程先完成一系列的操作，比如说加载数据页到缓存页，更新free链表，更新lru链表，然后释放锁，接着下一个线程再执行一系列的操作

- 多线程并发访问加锁，数据库的性能还能好吗

  - 因为大部分情况下，每个线程都是查询或者更新缓存页里的数据，这个操作是发生在内存里的，基本都是微秒级的，很快很快，包括更新free、flush、lru这些链表，他因为都是基于链表进行一些指针操作，性能也是极高的
  - 但是再怎么可以，你毕竟也是每个线程加锁然后排队一个一个操作，这也不是特别的好，特别是有的时候你的线程拿到锁之后，他可能要从磁盘里读取数据页加载到缓存页里去，这还发生了一次磁盘IO呢！所以他要是进行磁盘IO的话，也许耗时就会多一些，那么后面排队等他的线程自然就多等一会儿了

- MySQL的生产优化经验：多个Buffer Pool优化并发能力

  - 一般来说，MySQL默认的规则是，如果你给Buffer Pool分配的内存小于1GB，那么最多就只会给你一个Buffer Pool

  - 但是如果你的机器内存很大，那么你必然会给Buffer Pool分配较大的内存，比如给他个8G内存，那么此时你是同时可以设置多个Buffer Pool的，比如说下面的MySQL服务器端的配置

    ```
    [server]
    innodb_buffer_pool_size = 8589934592
    innodb_buffer_pool_instances = 4
    ```

  - 给buffer pool设置了8GB的总内存，然后设置了他应该有4个Buffer Pool，此时就是说，每个buffer pool的大小就是2GB。MySQL在运行的时候就会有4个Buffer Pool了！每个Buffer Pool负责管理一部分的缓存页和描述数据块，有自己独立的free、flush、lru等链表

  - 有了多个buffer pool之后，你的多线程并发访问的性能就会得到成倍的提升，因为多个线程可以在不同的buffer pool中加锁和执行自己的操作，大家可以并发来执行

#### 生产经验：如何通过chunk来支持数据库运行期间的Buffer Pool动态调整

- buffer pool这种大块头，能在运行期间动态调整大小吗
  - buffer pool是绝对不能支持运行期间动态调整大小的
- 如何基于chunk机制把buffer pool给拆小
  - 但是MySQL自然会想办法去做一些优化的，他实际上设计了一个chunk机制，也就是说buffer pool是由很多chunk组成的，他的大小是innodb_buffer_pool_chunk_size参数控制的，默认值就是128MB
  - 所以实际上我们可以来做一个假设，比如现在我们给buffer pool设置一个总大小是8GB，然后有4个buffer pool，那么每个buffer pool就是2GB，此时每个buffer pool是由一系列的128MB的chunk组成的，也就是说每个buffer pool会有16个chunk
  - 然后每个buffer pool里的每个chunk里就是一系列的描述数据块和缓存页，每个buffer pool里的多个chunk共享一套free、flush、lru这些链表
- 基于chunk机制是如何支持运行期间，动态调整buffer pool大小的
  - 比如我们buffer pool现在总大小是8GB，现在要动态加到16GB，那么此时只要申请一系列的128MB大小的chunk就可以了，只要每个chunk是连续的128MB内存就行了。然后把这些申请到的chunk内存分配给buffer pool就行了
  - 有个这个chunk机制，此时并不需要额外申请16GB的连续内存空间，然后还要把已有的数据进行拷贝

#### 生产经验：在生产环境中，如何基于机器配置来合理设置Buffer Pool

- 生产环境中应该给buffer pool设置多少内存
  - 通常来说，我们建议一个比较合理的、健康的比例，是给buffer pool设置你的机器内存的50%~60%左右。
  - 比如你有32GB的机器，那么给buffer设置个20GB的内存，剩下的留给OS和其他人来用，这样比较合理一些。假设你的机器是128GB的内存，那么buffer pool可以设置个80GB左右，大概就是这样的一个规则
- buffer pool总大小=(chunk大小 * buffer pool数量)的倍数
  - 接着确定了buffer pool的总大小之后，就得考虑一下设置多少个buffer pool，以及chunk的大小
  - 比如默认的chunk大小是128MB，那么此时如果你的机器的内存是32GB，你打算给buffer pool总大小在20GB左右，那么你得算一下，此时你的buffer pool的数量应该是多少个
    - 假设你的buffer pool的数量是16个，这是没问题的，那么此时chunk大小 * buffer pool的数量 = 16 * 128MB =2048MB，然后buffer pool总大小如果是20GB，此时buffer pool总大小就是2048MB的10倍
    - 此时你可以设置多一些buffer pool数量，比如设置32个buffer pool，那么此时buffer pool总大小（20GB）就是（chunk大小128MB * 32个buffer pool）的5倍
    - 那么此时你的buffer pool大小就是20GB，然后buffer pool数量是32个，每个buffer pool的大小是640MB，然后每个buffer pool包含5个128MB的chunk
- SHOW ENGINE INNODB STATUS
  - 一个是你的buffer pool的千次访问缓存命中率，这个命中率越高，说明你大量的操作都是直接基于缓存来执行的，性能越高
  - 第二个是你的磁盘IO的情况，这个磁盘IO越多，说明你数据库性能越差

#### 我们写入数据库的一行数据，在磁盘上是怎么存储的

- MySQL为什么要引入数据页这个概念
  - 当我们要执行update之类的SQL语句的时候，把磁盘上的一些数据加载到内存里来，然后对内存里的数据进行更新，同时写redo log到磁盘上去
  - innodb存储引擎在这里引入了一个数据页的概念，也就是把数据组织成一页一页的概念，每一页有16kb，然后每次加载磁盘的数据到内存里的时候，是至少加载一页数据进去，甚至是多页数据进去
  - 磁盘和内存之间的数据交换通过数据页来执行，包括内存里更新后的脏数据，刷回磁盘的时候，也是至少一个数据页刷回去
  - 当IO线程把内存里的脏数据刷到磁盘上去的时候，也是以数据页为单位来刷回去的
- MySQL物理数据存储格式：一行数据在磁盘上是如何存储的
  - 对于每一行数据，他其实存储的时候都会有一些头字段对这行数据进行一定的描述，然后再放上他这一行数据每一列的具体的值，这就是所谓的行格式。除了COMPACT以外，还有其他几种行存储格式，基本都大同小异

#### 对于VARCHAR这种变长字段，在磁盘上到底是如何存储的

- 变长字段在磁盘中是怎么存储的
  - 数据放在一个磁盘文件里都挨着存储的
- 存储在磁盘文件里的变长字段，为什么难以读取
  - 在不知道一行数据的每个字段到底是多少长度的情况下，胡乱的去读取是不现实的，根本不知道磁盘文件里混成一坨的数据里，哪些数据是你要读取的一行
- 引入变长字段的长度列表，解决一行数据的读取问题
- 引入变长字段长度列表后，如何解决变长字段的读取问题
  - 所以假设此时你要读取“hello a a”这行数据，你首先会知道这个表里的三个字段的类型是VARCHAR(10) CHAR(1) CHAR(1)，那么此时你先要读取第一个字段的值，那么第一个字段是变长的，到底他的实际长度是多少呢
  - 此时你会发现第一行数据的开头有一个变长字段的长度列表，里面会读取到一个0x05这个十六进制的数字，发现第一个变长字段的长度是5，于是按照长度为5，读取出来第一个字段的值，就是“hello”
  - 接着你知道后续两个字段都是CHAR(1)，长度都是固定的1个字符，于是此时就依次按照长度为1读取出来后续两个字段的值，分别是“a”“a”，于是最终你会读取出来“hello a a”这一行数据
  - 接着假设你要读取第二行数据，你先看一下第二行数据后的变长字段长度列表，发现他第一个变长字段的长度是0x02，于是就读取长度为2的字段值，就是“hi”，再读取两个长度固定为1的字符值，都是“a”，此时读取出来“hi a a”这行数据
- 如果有多个变长字段，如何存放他们的长度
  - 比如一行数据有VARCHAR(10) VARCHAR(5) VARCHAR(20) CHAR(1) CHAR(1)，一共5个字段，其中三个是变长字段，此时假设一行数据是这样的：hello hi hao a a
  - 此时在磁盘中存储的，必须在他开头的变长字段长度列表中存储几个变长字段的长度，一定要注意一点，他这里是逆序存储的
  - 也就是说先存放VARCHAR(20)这个字段的长度，然后存放VARCHAR(5)这个字段的长度，最后存放VARCHAR(10)这个字段的长度
  - 现在hello hi hao三个字段的长度分别是0x05 0x02 0x03，但是实际存放在变长字段长度列表的时候，是逆序放的，所以一行数据实际存储可能是下面这样的：0x03 0x02 0x05 null值列表 头字段 hello hi hao a a
- 今日思考题
  - 为什么MySQL在把一行一行的数据存储在磁盘上的时候，要采取这种“0x05 null值列表数据头 hello a a 0x02 null值列表 数据头 hi a a”很多行数据都仅仅挨在一起的方式
  - 为什么MySQL不能用Java里面的序列化的那种方式？把很多行的数据做成一个大的对象，然后给他序列化一下写入到磁盘文件里，从磁盘里读取的时候压根儿不用care什么行存储格式，直接反序列化一下，把数据就可以从磁盘文件里拿回来了
  - MySQL用这种数据紧凑挨在一起的方式来存储数据，到底有什么好处

#### 一行数据中的多个NULL字段值在磁盘上怎么存储

- 为什么一行数据里的NULL值不能直接存储
  - 磁盘上存储的一行数据里另外一块特殊的数据区域，就是NULL值列表。就是你一行数据里可能有的字段值是NULL，比如你有一个name字段，他是允许为NULL的，那么实际上在存储的时候，如果你没给他赋值，他这个字段的值就是NULL
  - 实际在磁盘上存储数据的时候，一行数据里的NULL值是肯定不会直接按照字符串的方式存放在磁盘上浪费空间的
- NULL值是以二进制bit位来存储的
  - 对所有的NULL值，不通过字符串在磁盘上存储，而是通过二进制的bit位来存储，一行数据里假设有多个字段的值都是NULL，那么这多个字段的NULL，就会以bit位的形式存放在NULL值列表中
- 结合小小案例来思考一行数据的磁盘存储格式
  - 变长字段长度列表 NULL值列表 头信息 column1=value1 column2=value2 ... columnN=valueN
  - 要区分一个问题，那就是如果这个变长字段的值是NULL，就不用在变长字段长度列表里存放他的值长度了，所以在上面那行数据中，只有name和school两个变长字段是有值的，把他们的长度按照逆序放在变长字段长度列表中就可以了，如下所示：0x09 0x04 NULL值列表 头信息 column1=value1  column2=value2 ... columnN=valueN
  - 接着来看NULL值列表，这个NULL值列表是这样存放的，你所有允许值为NULL的字段，注意，是允许值为NULL，不是说一定值就是NULL了，只要是允许你为NULL的字段，在这里每个字段都有一个二进制bit位的值，如果bit值是1说明是NULL，如果bit值是0说明不是NULL
  - 比如上面4个字段都允许为NULL，每个人都会有一个bit位，这一行数据的值是“jack NULL m NULL xx_school”，然后其中2个字段是null，2个字段不是null，所以4个bit位应该是：1010
  - 但是实际放在NULL值列表的时候，他是按逆序放的，所以在NULL值列表里，放的是：0101，整体这一行数据看着是下面这样的：0x09 0x04 0101 头信息 column1=value1 column2=value2 ... columnN=valueN
  - 另外就是他实际NULL值列表存放的时候，不会说仅仅是4个bit位，他一般起码是8个bit位的倍数，如果不足8个bit位就高位补0，所以实际存放看起来是如下的：0x09 0x04 00000101 头信息 column1=value1 column2=value2 ... columnN=valueN
- 磁盘上的一行数据到底如何读取出来的
  - 再看上面的磁盘数据存储格式：0x09 0x04 00000101 头信息 column1=value1 column2=value2 ... columnN=valueN
  - 首先他必然要把变长字段长度列表和NULL值列表读取出来，通过综合分析一下，就知道有几个变长字段，哪几个变长字段是NULL，因为NULL值列表里谁是NULL谁不是NULL都一清二楚
  - 此时就可以从变长字段长度列表中解析出来不为NULL的变长字段的值长度，然后也知道哪几个字段是NULL的，此时根据这些信息，就可以从实际的列值存储区域里，把你每个字段的值读取出来了
  - 如果是变长字段的值，就按照他的值长度来读取，如果是NULL，就知道他是个NULL，没有值存储，如果是定长字段，就按照定长长度来读取，这样就可以完美的把你一行数据的值都读取出来了
- 今日思考题
  - 为什么NULL值列表要按照二进制bit位的方式来存储

#### 磁盘文件中， 40个bit位的数据头以及真实数据是如何存储的

- 每一行数据存储的时候，还得有40个bit位的数据头，这个数据头是用来描述这行数据的
  - 这40个bit位里，第一个bit位和第二个bit位，都是预留位，是没任何含义的
  - 然后接下来有一个bit位是delete_mask，他标识的是这行数据是否被删除了，这么说在MySQL里删除一行数据的时候，未必是立马把他从磁盘上清理掉，而是给他在数据头里搞1个bit标记他已经被删了
  - 然后下一个bit位是min_rec_mask，这个bit位大家现在先不用去关注，他的含义以后我们讲到对应的内容的时候再说，他其实就是说在B+树里每一层的非叶子节点里的最小值都有这个标记
  - 接下来有4个bit位是n_owned，这个暂时我们也先不用去管他，他其实就是记录了一个记录数
  - 接着有13个bit位是heap_no，他代表的是当前这行数据在记录堆里的位置
  - 然后是3个bit位的record_type，这就是说这行数据的类型：0代表的是普通类型，1代表的是B+树非叶子节点，2代表的是最小值数据，3代表的是最大值数据
  - 最后是16个bit的next_record，这个是指向他下一条数据的指针

#### 我们每一行的实际数据在磁盘上是如何存储的

- 一行数据在磁盘文件里存储的时候，实际上首先会包含自己的变长字段的长度列表，然后是NULL值列表，接着是数据头，然后接着才是真实数据
- 比如我们之前说了一个例子，有一行数据是“jack NULL m NULL xx_school”，那么他真实存储大致如下所示：
  0x09 0x04 00000101 0000000000000000000010000000000000011001 jack m xx_school
- 刚开始先是他的变长字段的长度，用十六进制来存储，然后是NULL值列表，指出了谁是NULL，接着是40个bit位的数据头，然后是真实的数据值，就放在后面
- 实际上字符串这些东西都是根据我们数据库指定的字符集编码，进行编码之后再存储的，所以大致看起来一行数据是如下所示的：0x09 0x04 00000101 0000000000000000000010000000000000011001 616161 636320 6262626262
- 在实际存储一行数据的时候，会在他的真实数据部分，加入一些隐藏字段，这个隐藏字段跟后续的一些内容是有关联的
  - 首先有一个DB_ROW_ID字段，这就是一个行的唯一标识，是他数据库内部给你搞的一个标识，不是你的主键ID字段。如果我们没有指定主键和unique key唯一索引的时候，他就内部自动加一个ROW_ID作为主键
  - 接着是一个DB_TRX_ID字段，这是跟事务相关的，他是说这是哪个事务更新的数据，这是事务ID
  - 最后是DB_ROLL_PTR字段，这是回滚指针，是用来进行事务回滚的

#### 理解数据在磁盘上的物理存储之后，聊聊行溢出是什么东西

- 比如有一个表的字段类型是VARCHAR(65532)，意思就是最大可以包含65532个字符，那也就是65532个字节，这就远大于16kb的大小了，也就是说这一行数据的这个字段都远超一个数据页的大小了
  - 这个时候实际上会在那一页里存储你这行数据，然后在那个字段中，仅仅包含他一部分数据，同时包含一个20个字节的指针，指向了其他的一些数据页，那些数据页用链表串联起来，存放这个VARCHAR(65532)超大字段里的数据。其实就叫做行溢出，就是说一行数据存储的内容太多了，一个数据页都放不下了，此时只能溢出这个数据页，把数据溢出存放到其他数据页里去，那些数据页就叫做溢出页
- 包括其他的一些字段类型都是一样的，比如TEXT、BLOB这种类型的字段，都有可能出现溢出，然后一行数据就会存储在多个数据页里
- 总结
  - 当我们在数据库里插入一行数据的时候，实际上是在内存里插入一个有复杂存储结构的一行数据，然后随着一些条件的发生，这行数据会被刷到磁盘文件里去
  - 在磁盘文件里存储的时候，这行数据也是按照复杂的存储结构去存放的
  - 每一行数据都是放在数据页里的，如果一行数据太大了，就会产生行溢出问题，导致一行数据溢出到多个数据页里去，那么这行数据在Buffer Pool可能就是存在于多个缓存页里的，刷入到磁盘的时候，也是用磁盘上的多个数据页来存放这行数据的

#### 用于存放磁盘上的多行数据的数据页到底长个什么样子

- 其实一个数据页拆分成了很多个部分，大体上来说包含了文件头、数据页头、最小记录和最大记录、多个数据行、空闲空间、数据页目录、文件尾部
- 其中文件头占据了38个字节，数据页头占据了56个字节，最大记录和最小记录占据了26个字节，数据行区域的大小是不固定的，空闲区域的大小也是不固定的，数据页目录的大小也是不固定的，然后文件尾部占据8个字节

#### 表空间以及划分多个数据页的数据区，又是什么概念

- 什么是表空间
  - 简单来说，就是我们平时创建的那些表，其实都是有一个表空间的概念，在磁盘上都会对应着“表名.ibd”这样的一个磁盘数据文件
  - 所以其实在物理层面，表空间就是对应一些磁盘上的数据文件。有的表空间，比如系统表空间可能对应的是多个磁盘文件，有的我们自己创建的表对应的表空间可能就是对应了一个“表名.ibd”数据文件
  - 一个表空间的磁盘文件里，其实是有很多的数据页的
- 但是现在有一个问题，就是一个表空间里包含的数据页实在是太多了，不便于管理，所以在表空间里又引入了一个数据区的概念，英文就是extent
  - 一个数据区对应着连续的64个数据页，每个数据页是16kb，所以一个数据区是1mb，然后256个数据区被划分为了一组
  - 对于表空间而言，他的第一组数据区的第一个数据区的前3个数据页，都是固定的，里面存放了一些描述性的数据。比如FSP_HDR这个数据页，他里面就存放了表空间和这一组数据区的一些属性。IBUF_BITMAP数据页，里面存放的是这一组数据页的所有insert buffer的一些信息。INODE数据页，这里也是存放了一些特殊的信息
  - 然后这个表空间里的其他各组数据区，每一组数据区的第一个数据区的头两个数据页，都是存放特殊信息的，比如XDES数据页就是用来存放这一组数据区的一些相关属性的，其实就是很多描述这组数据区的东西
- 总结
  - 我们平时创建的那些表都是有对应的表空间的，每个表空间就是对应了磁盘上的数据文件，在表空间里有很多组数据区，一组数据区是256个数据区，每个数据区包含了64个数据页，是1mb
  - 然后表空间的第一组数据区的第一个数据区的头三个数据页，都是存放特殊信息的
  - 表空间的其他组数据区的第一个数据区的头两个数据页，也都是存放特殊信息的
  - 所以磁盘上的各个表空间的数据文件里是通过数据区的概念，划分了很多很多的数据页的，因此当我们需要执行crud操作的时候，说白了，就是从磁盘上的表空间的数据文件里，去加载一些数据页出来到Buffer Pool的缓存页里去使用

#### 一文总结初步了解到的MySQL存储模型以及数据读写机制

- MySQL的数据都是放在磁盘文件里的
- 数据在磁盘文件里是怎么存放的
  - MySQL的磁盘上，表空间就对应着磁盘文件，在磁盘文件里就存放着数据
- 表空间的磁盘文件里，数据是如何组织的
  - 所以其实在磁盘文件里存放的数据，他从最基本的角度来看的话，就是被拆分为一个一个的数据区（extent）分组，以后我们干脆就用他的英文名叫做extent组好了，每个extent组中包含256个extent，然后每个extent里包含64个数据页！然后每个数据页里都包含了一行一行的数据
  - 在实际存储的时候，我们之前稍微给大家介绍过一点点，在数据行里都有很多附加的信息，在数据页、数据区里，都有很多附加的特殊信息。各种各样的特殊信息，就可以让我们在简简单单的磁盘文件里实现B+树索引、事务之类的非常复杂的机制
- 当我们在数据库中执行crud的时候，你必须先把磁盘文件里的一个数据页加载到内存的Buffer Pool的一个缓存页里去，然后我们增删改查都是针对缓存页里的数据来执行的
- 假设此时我们要插入一条数据，那么是选择磁盘文件里的哪个数据页加载到缓存页里去
  - 其实这个时候会看看你往哪个表里插入数据？然后肯定得根据表找到一个表空间，找到表空间之后，就可以定位到对应的磁盘文件。有了磁盘文件之后，就可以从里面找一个extent组，找一个extent，接着从里面找一个数据页出来。这个数据也可能是空的，也可能已经放了一些数据行了。然后就可以把这个数据页从磁盘里完整加载出来，放入Buffer Pool的缓存页里
- 从磁盘文件里读取一个数据页，是怎么读取的
  - 在读取一个数据页的时候，你就可以通过随机读写的方式，设置一下要从一个数据文件的哪个位置开始读取，一直到哪个位置就结束。指定磁盘文件里的开始和截止的位置，就能读取出来指定位置的一段数据。然后把数据页放到内存的缓存页里即可
- 对于那些被更新过的缓存页来说，都会由后台线程刷入磁盘的，那么刷磁盘的时候是怎么刷
  - 因为一个数据页的大小其实是固定的，所以一个数据页固定就是可能在一个磁盘文件里占据了某个开始位置到结束位置的一段数据，此时你写回去的时候也是一样的，选择好固定的一段位置的数据，直接把缓存页的数据写回去，就覆盖掉了原来的那个数据页了

#### 思考题

- 不同的存储引擎是用来干什么的
- 执行更新操作的时候，为什么不能执行修改磁盘上的数据
  - 因为来一个请求就直接对磁盘文件进行随机读写，然后更新磁盘文件里的数据，虽然技术上是可以做到的，但是那必然导致执行请求的性能极差
  - 因为磁盘随机读写的性能是最差的，所以直接更新磁盘文件，必然导致我们的数据库完全无法抗下任何一点点稍微高并发一点的场景
  - 所以MySQL才设计了如此复杂的一套机制，通过内存里更新数据，然后写redo log以及事务提交，后台线程不定时刷新内存里的数据到磁盘文件里
  - 通过这种方式保证，你每个更新请求，尽量就是更新内存，然后顺序写日志文件
  - 更新内存的性能是极高的，然后顺序写磁盘上的日志文件的性能也是比较高的，因为顺序写磁盘文件，他的性能要远高于随机读写磁盘文件
- 为什么MySQL在更新数据的时候，要大费周章的搞这么多事情，包括buffer pool、redo log、undo log、
  binlog、事务提交、脏数据。引入了一大堆的概念，有复杂的流程和步骤
- 为什么他反而最关键的修改磁盘里的数据，要通过IO线程不定时的去执行
- 为什么他不干脆直接就每次执行SQL语句，直接就更新磁盘里的数据
- 我们写 SQL 的时候，只知道表 + 行的概念，但是在 MySQL 内部操作的时候，是表空间 + 数据页的概念，两者之间的区别是什么、他们之间的联系是什么
  - 一个是逻辑概念，一个是物理概念
  - 表、列和行，都是逻辑概念，我们只知道数据库里有一个表，表里有几个字段，有多少行，但是这些表里的数据，在数据库的磁盘上如何存储的，你知道吗？我们是不关注的，所以他们都是逻辑上的概念
  - 表空间、数据页，这些东西，都是物理上的概念，实际上在物理层面，你的表里的数据都放在一个表空间中，表空间是由一堆磁盘上的数据文件组成的，这些数据文件里都存放了你表里的数据，这些数据是由一个一个的数据页组织起来的，这些都是物理层面的概念
- 对于 Buffer Pool 而言，他里面会存放很多的缓存页以及对应的描述数据，那么假设 Buffer Pool 里的内存
  都用尽了，已经没有足够的剩余内存来存放缓存页和描述数据了，此时 Buffer Pool 里就一点内存都没有了吗？还是说 Buffer Pool里会残留一些内存碎片呢？如果你觉得 Buffer Pool 里会有内存碎片的话，那么你觉得应该怎么做才能尽可能减少 Buffer Pool 里的内存碎片呢
  - 有内存碎片：因为 Buffer Pool 大小是你自己定的，很可能 Buffer Pool 划分完全部的缓存页和描述数据块之后，还剩一点点的内存，这一点点的内存放不下任何一个缓存页了，所以这点内存就只能放着不能用，这就是内存碎片
  - 减少内存碎片：数据库在 Buffer Pool 中划分缓存页的时候，会让所有的缓存页和描述数据块都紧密的挨在一起，这样尽可能减少内存浪费，就可以尽可能的减少内存碎片的产生了。如果你的 Buffer Pool 里的缓存页是东一块西一块，那么必然导致缓存页的内存之间有很多内存空隙，这就会有大量的内存碎片了
- 为什么MySQL要设计预读这个机制？加载一个数据页到缓存里去的时候，为什么要把一些相邻的数据页也加载到缓存里去呢？ 这么做的意义在哪里？是为了应对什么样的一个场景
  - 为了优化性能，MySQL 才设计了预读机制，也就是说如果在一个区内，你顺序读取了好多数据页了，比如数据页 01~数据页 56 都被你依次顺序读取了，MySQL 会判断，你可能接着会继续顺序读取后面的数据页
- 基于这套冷热数据隔离的方案，LRU 链表的冷数据区域放的都是什么样的缓存页
  - 大部分应该都是预读加载进来的缓存页，加载进来 1s 之后都没人访问的，然后包括全表扫描或者一些大的查询语句，加载一堆数据到缓存页，结果都是 1s 之内访问了一下，后续就不再访问这些表的数据
- 对于我们开发的 Java 系统，如果在 Redis 里存放了很多缓存数据，那么此时会不会有类似冷热数据的问题？应该如何优化和解决
  - 那必然是存在一些问题的
  - 常见的一个场景就是电商系统里的商品缓存数据，假设你有1亿个商品，然后只要查询商品的时候发现商品不在缓存里，就给他放到缓存里去，你要这么搞的话，必然导致大量的不怎么经常访问的商品会被放在 Redis 缓存里
  - 经常被访问的商品其实就是热数据，不经常被访问的商品其实就是冷数据，我们应该尽量让 Redis 里放的都是经常访问的热数据，而不是大量的冷数据。因为你放一大堆不怎么经常访问的商品在 Redis 里，那么他占用了很多内存，而且后续还不怎么会访问到他们
  - 设计缓存机制的时候，经常会考虑热数据的缓存预加载：每天统计出来哪些商品被访问的次数最多，然后晚上的时候，系统启动一个定时作业，把这些热门商品的数据，预加载到 Redis 里。 那么第二天是不是对热门商品的访问就自然会优先走 Redis 缓存了
- 如果一个缓存页在冷数据区域的尾巴上，已经超过 1s 了，此时这个缓存页被访问了一下，那么他此时会移动到冷数据区域的链表头部吗
- 你的MySQL的内核参数，应该如何优化，优化哪些地方的行为，才能够尽可能的避免在执行CRUD的时候，经常要先刷一个缓存页到磁盘上去，才能读取一个磁盘上的数据页到空闲缓存页里来
  - 线上的MySQL在生产环境中，buffer pool的大小、buffer pool的数量，这都是要用心设置和优化的